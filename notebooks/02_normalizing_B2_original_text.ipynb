{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing B2 original text\n",
    "\n",
    "<br>\n",
    "\n",
    "**Language: Python**\n",
    "\n",
    "This notebook shows the process used for creating the length-normalized B2 text from the original public IELTS Task 2 B2 text. The original text is a public academic writing sample from the [IELTS website](https://www.ielts.org/en-us/about-the-test/sample-test-questions). The original text is 349 words and the desired length is 250 words (see chapters 5.1 and 5.2 of the dissertation).\n",
    "\n",
    "**Notebook contents:**\n",
    "- [Initial setup](#Initial-setup)\n",
    "- [Text processing](#Text-processing)\n",
    "- [Syntactic complexity](#Syntactic-complexity)\n",
    "- [Lexical diversity](#Lexical-diversity)\n",
    "- [Lexical sophistication](#Lexical-sophistication)\n",
    "- [Collocation measures](#Collocation-measures)\n",
    "- [Accuracy](#Accuracy)\n",
    "- [Normalizing length](#Normalizing-length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import csv\n",
    "from ast import literal_eval\n",
    "from nltk import pos_tag_sents\n",
    "from pelitk import lex\n",
    "import joblib\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "from CLAWSTag import Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "# Set preferred notebook format\n",
    "\n",
    "%pprint # Turn off pretty printing\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # Show all output, not just last item\n",
    "pd.set_option('display.max_columns', 999) # Allow viewing of all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** As described in the [README.md]('../README.md'), The frequency information from COCA referenced here is not freely available but can be purchased at https://corpus.byu.edu/coca. Without this data you will be able to see a few rows of these dataframes, but will not be able to run the code yourself. The t-scores and K-bands were also calculated using these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary dictionaries\n",
    "\n",
    "coca_freq_dict = joblib.load('../../COCA_data/COCA_2020_lemma_freq_dict.pkl')\n",
    "coca_word_lemma_dict = joblib.load('../../COCA_data/COCA_2020_word_lemma_dict.pkl')\n",
    "col_freq_dict = joblib.load('../../COCA_data/COCA_2020_collocate_freq_dict.pkl')\n",
    "MI_dict = joblib.load('../../COCA_data/COCA_2020_MI_dict.pkl')\n",
    "tscore_dict = joblib.load('../../COCA_data/COCA_2020_tscore_dict.pkl')\n",
    "kband_dict = joblib.load('../../COCA_data/COCA_2020_lemma_Kband_dict.pkl') # All items lower-case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in original text (transcribed and with corrected spelling)\n",
    "\n",
    "f = open(\"../docs/B2_original_corrected.txt\", \"r\")\n",
    "B2_orig = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In addition to correcting spelling, contractions were changed to full words, '&' to 'and', '20' to 'twenty', and 'Mr' to 'Mister'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in modified text\n",
    "\n",
    "f = open(\"../docs/B2_normalized.txt\", \"r\")\n",
    "B2_norm = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** These modified texts were modified based on the [`Normalizing length`](#Normalizing-length) goals described later, but are incorporated here to avoid having to go through the text processing procedure twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B2_orig</td>\n",
       "      <td>I greatly support the idea. I support it, beca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2_norm</td>\n",
       "      <td>I greatly support the idea.\\nraised in a certa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text\n",
       "0  B2_orig  I greatly support the idea. I support it, beca...\n",
       "1  B2_norm  I greatly support the idea.\\nraised in a certa..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe\n",
    "\n",
    "texts_df = pd.DataFrame({'text_id':pd.Series(['B2_orig','B2_norm']),\n",
    "                         'text':pd.Series([B2_orig,B2_norm])})\n",
    "\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing\n",
    "\n",
    "The tokenizer, part-of-speech tagger, and lemmatizer tools are the same ones used in the creation of the [PELIC](https://github.com/ELI-Data-Mining-Group/PELIC-dataset) corpus. The tokenizer and lemmatizer are not open access but are based on the ones from [NLTK](https://www.nltk.org/), and using the public NLTK tools will yield similar results. For a more detailed description of the modified tools, please see [Naismith et al. (2022)](https://benjamins.com/catalog/ijlcr.21002.nai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Ben/Documents/ELI_Data_Mining/Data-Archive/elitools\n"
     ]
    }
   ],
   "source": [
    "# Change to working directory containing elitools\n",
    "\n",
    "%cd '../../ELI_Data_Mining/Data-Archive/elitools/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lemmatizer\n",
    "\n",
    "%run -i 'lemmatizer_class.py'\n",
    "lemmatizer = lemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer module\n",
    "\n",
    "%run -i 'tokenizer.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Ben/Documents/Collocational_proficiency_Naismith_2022/notebooks\n"
     ]
    }
   ],
   "source": [
    "# Return to previous working directory\n",
    "\n",
    "%cd '../../../Collocational_proficiency_Naismith_2022/notebooks'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B2_orig</td>\n",
       "      <td>I greatly support the idea. I support it, beca...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2_norm</td>\n",
       "      <td>I greatly support the idea.\\nraised in a certa...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raised, in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B2_orig  I greatly support the idea. I support it, beca...   \n",
       "1  B2_norm  I greatly support the idea.\\nraised in a certa...   \n",
       "\n",
       "                                                toks  \n",
       "0  [I, greatly, support, the, idea, ., I, support...  \n",
       "1  [I, greatly, support, the, idea, ., raised, in...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize text (nltk-based)\n",
    "\n",
    "texts_df['toks'] = texts_df.text.apply(tokenize)\n",
    "\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tagging\n",
    "- NLTK (PELIC)\n",
    "- CLAWS7 (COCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK\n",
    "As there are only three texts (each with three versions), to avoid any errors, I have used the default NLTK tagger (Penn Treebank tagset), then manually checked and corrected the tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply nltk tagger to create series\n",
    "\n",
    "B2_NLTK = pd.Series(pos_tag_sents(texts_df['toks']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-211653fdc074>:7: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  B2_NLTK_CHECKED = pd.read_csv(\"../docs/B2_NLTK_CHECKED.csv\", header=None, squeeze = True)\n"
     ]
    }
   ],
   "source": [
    "# Check tags\n",
    "\n",
    "# Write out tagged texts\n",
    "B2_NLTK.to_csv('../docs/B2_NLTK.csv', index=False, header=False) \n",
    "\n",
    "# Read in the checked tagged texts as a series\n",
    "B2_NLTK_CHECKED = pd.read_csv(\"../docs/B2_NLTK_CHECKED.csv\", header=None, squeeze = True) \n",
    "B2_NLTK_CHECKED = [literal_eval(x) for x in B2_NLTK_CHECKED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B2_orig</td>\n",
       "      <td>I greatly support the idea. I support it, beca...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2_norm</td>\n",
       "      <td>I greatly support the idea.\\nraised in a certa...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raised, in...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B2_orig  I greatly support the idea. I support it, beca...   \n",
       "1  B2_norm  I greatly support the idea.\\nraised in a certa...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raised, in...   \n",
       "\n",
       "                                        tok_POS_NLTK  \n",
       "0  [(I, PRP), (greatly, RB), (support, VBP), (the...  \n",
       "1  [(I, PRP), (greatly, RB), (support, VBP), (the...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create column based on checked tagged texts\n",
    "\n",
    "texts_df['tok_POS_NLTK'] = B2_NLTK_CHECKED\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLAWS7\n",
    "\n",
    "By also tagging with CLAWS7, it is easier to match the POS to the COCA info, rather than the Penn tagset used by NLTK and then having to convert.\n",
    "\n",
    "Free CLAWS tagger: http://ucrel-api.lancaster.ac.uk/claws/free.html\n",
    "\n",
    "Again, these tagged texts should be manually checked prior to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in tagged CLAWS texts\n",
    "\n",
    "f = open(\"../docs/B2_original_CLAWS.txt\", \"r\")\n",
    "B2_orig_CLAWS = f.read()\n",
    "\n",
    "f = open(\"../docs/B2_normalized_CLAWS.txt\", \"r\")\n",
    "B2_norm_CLAWS = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove new line characters, split on whitespace, and remove identifier at end\n",
    "\n",
    "B2_orig_CLAWS = B2_orig_CLAWS.replace('\\n', '').split(' ')[:-2]\n",
    "B2_norm_CLAWS = B2_norm_CLAWS.replace('\\n', '').split(' ')[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change tags into tuples\n",
    "\n",
    "B2_orig_CLAWS = [tuple(x.split('_')) for x in B2_orig_CLAWS]\n",
    "B2_norm_CLAWS = [tuple(x.split('_')) for x in B2_norm_CLAWS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B2_orig</td>\n",
       "      <td>I greatly support the idea. I support it, beca...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, PPIS1), (greatly, RR), (support, VV0), (t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2_norm</td>\n",
       "      <td>I greatly support the idea.\\nraised in a certa...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raised, in...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, PPIS1), (greatly, RR), (support, VV0), (t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B2_orig  I greatly support the idea. I support it, beca...   \n",
       "1  B2_norm  I greatly support the idea.\\nraised in a certa...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raised, in...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "1  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \n",
       "0  [(I, PPIS1), (greatly, RR), (support, VV0), (t...  \n",
       "1  [(I, PPIS1), (greatly, RR), (support, VV0), (t...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df['toks_POS_CLAWS'] = pd.Series([B2_orig_CLAWS,B2_norm_CLAWS])\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B2_orig</td>\n",
       "      <td>I greatly support the idea. I support it, beca...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, PPIS1), (greatly, RR), (support, VV0), (t...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2_norm</td>\n",
       "      <td>I greatly support the idea.\\nraised in a certa...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raised, in...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, PPIS1), (greatly, RR), (support, VV0), (t...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raise, in,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B2_orig  I greatly support the idea. I support it, beca...   \n",
       "1  B2_norm  I greatly support the idea.\\nraised in a certa...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raised, in...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "1  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, PPIS1), (greatly, RR), (support, VV0), (t...   \n",
       "1  [(I, PPIS1), (greatly, RR), (support, VV0), (t...   \n",
       "\n",
       "                                         lemmas_NLTK  \n",
       "0  [I, greatly, support, the, idea, ., I, support...  \n",
       "1  [I, greatly, support, the, idea, ., raise, in,...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create lemmatized text column using our lemmatizer loaded earlier\n",
    "\n",
    "texts_df['lemmas_NLTK'] = texts_df['tok_POS_NLTK'].apply(lemmatizer.lemmatize_text)\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLAWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only first letter of CLAWS PoS tags\n",
    "\n",
    "texts_df.toks_POS_CLAWS = texts_df.toks_POS_CLAWS.apply(lambda row: [(x[0],x[1][0].lower()) for x in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove puncuation from CLAWS texts\n",
    "\n",
    "COCA_POS = sorted(list(set([x[1] for x in coca_freq_dict.keys()])))\n",
    "texts_df.toks_POS_CLAWS = texts_df.toks_POS_CLAWS.apply(lambda row: [x for x in row if x[1] in COCA_POS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('everyday', 'r')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check lemmas not in COCA dict\n",
    "\n",
    "sorted(list(set([x for y in texts_df.toks_POS_CLAWS.apply(lambda row: [x for x in row if (x[0].lower(),x[1]) not in coca_word_lemma_dict]).to_list() for x in y])))\n",
    "\n",
    "# Used as 'every day' (adverb) rather than 'everyday' (adjective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B2_orig</td>\n",
       "      <td>I greatly support the idea. I support it, beca...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2_norm</td>\n",
       "      <td>I greatly support the idea.\\nraised in a certa...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raised, in...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raise, in,...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B2_orig  I greatly support the idea. I support it, beca...   \n",
       "1  B2_norm  I greatly support the idea.\\nraised in a certa...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raised, in...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "1  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (greatly, r), (support, v), (the, a),...   \n",
       "1  [(I, p), (greatly, r), (support, v), (the, a),...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raise, in,...   \n",
       "\n",
       "                                        lemmas_CLAWS  \n",
       "0  [(I, p), (greatly, r), (support, v), (the, a),...  \n",
       "1  [(I, p), (greatly, r), (support, v), (the, a),...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create CLAWS lemma column\n",
    "\n",
    "# First lower case all toks (as in the word_lemma dict)\n",
    "texts_df['lemmas_CLAWS'] = texts_df.toks_POS_CLAWS.apply(lambda row: [(x[0].lower(),x[1]) for x in row])\n",
    "\n",
    "# Then map dict\n",
    "texts_df.lemmas_CLAWS = texts_df.lemmas_CLAWS.apply(\n",
    "    lambda row:[coca_word_lemma_dict[x] if x in coca_word_lemma_dict else x for x in row])\n",
    "\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length\n",
    "Length counted manually rather than using the len(toks) or other RE-based counting. This is to ensure accuracy that would match how words are counted on IELTS tests (also done manually by examiners). These counts often match what Microsoft Word would provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary\n",
    "\n",
    "text_len = {'B2_orig':349,'B2_norm':250}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B2_orig</td>\n",
       "      <td>I greatly support the idea. I support it, beca...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2_norm</td>\n",
       "      <td>I greatly support the idea.\\nraised in a certa...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raised, in...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raise, in,...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B2_orig  I greatly support the idea. I support it, beca...   \n",
       "1  B2_norm  I greatly support the idea.\\nraised in a certa...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raised, in...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "1  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (greatly, r), (support, v), (the, a),...   \n",
       "1  [(I, p), (greatly, r), (support, v), (the, a),...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raise, in,...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len  \n",
       "0  [(I, p), (greatly, r), (support, v), (the, a),...       349  \n",
       "1  [(I, p), (greatly, r), (support, v), (the, a),...       250  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create length column\n",
    "\n",
    "texts_df['text_len'] = texts_df.text_id.map(text_len)\n",
    "texts_df['text_len'] = texts_df['text_len'].astype(int)\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic complexity\n",
    "\n",
    "Analysis using [TAASSC](https://www.linguisticanalysistools.org/taassc.html), calculating the measures from Lu's (2010) [Syntactic Complexity Analyzer](https://aihaiyang.com/software/). Based on previous research, two metrics most important for predicting proficiency are the focus: Number of complex nominals per clause (CN/C), and Mean length of clause (MLC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in TAASSC analysis file\n",
    "\n",
    "TAASSC = pd.read_csv(\"../docs/B2_TAASSC_sca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>nwords</th>\n",
       "      <th>MLS</th>\n",
       "      <th>MLT</th>\n",
       "      <th>MLC</th>\n",
       "      <th>C_S</th>\n",
       "      <th>VP_T</th>\n",
       "      <th>C_T</th>\n",
       "      <th>DC_C</th>\n",
       "      <th>DC_T</th>\n",
       "      <th>T_S</th>\n",
       "      <th>CT_T</th>\n",
       "      <th>CP_T</th>\n",
       "      <th>CP_C</th>\n",
       "      <th>CN_T</th>\n",
       "      <th>CN_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2_norm</td>\n",
       "      <td>256</td>\n",
       "      <td>17.066667</td>\n",
       "      <td>15.058824</td>\n",
       "      <td>7.314286</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.529412</td>\n",
       "      <td>2.058824</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>1.647059</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B2_orig</td>\n",
       "      <td>357</td>\n",
       "      <td>15.521739</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>2.130435</td>\n",
       "      <td>2.480000</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.086957</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>1.680000</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  nwords        MLS        MLT       MLC       C_S      VP_T  \\\n",
       "1  B2_norm     256  17.066667  15.058824  7.314286  2.333333  2.529412   \n",
       "3  B2_orig     357  15.521739  14.280000  7.285714  2.130435  2.480000   \n",
       "\n",
       "        C_T      DC_C      DC_T       T_S      CT_T      CP_T      CP_C  \\\n",
       "1  2.058824  0.457143  0.941176  1.133333  0.588235  0.117647  0.057143   \n",
       "3  1.960000  0.408163  0.800000  1.086957  0.520000  0.120000  0.061224   \n",
       "\n",
       "       CN_T      CN_C  \n",
       "1  1.647059  0.800000  \n",
       "3  1.680000  0.857143  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename files to match texts_df\n",
    "\n",
    "file_names = {'B2_original_corrected.txt':'B2_orig','B2_normalized.txt':'B2_norm'}\n",
    "TAASSC.filename = TAASSC.filename.map(file_names)\n",
    "TAASSC = TAASSC.loc[~TAASSC.filename.isnull()]\n",
    "TAASSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2_norm</td>\n",
       "      <td>7.314286</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B2_orig</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id       MLC       CNC\n",
       "1  B2_norm  7.314286  0.800000\n",
       "3  B2_orig  7.285714  0.857143"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only relevant syntactic complexity columns and rename them\n",
    "\n",
    "TAASSC = TAASSC[['filename','MLC','CN_C']]\n",
    "TAASSC = TAASSC.rename(columns={\"filename\": \"text_id\",'CN_C':'CNC'})\n",
    "TAASSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B2_orig</td>\n",
       "      <td>I greatly support the idea. I support it, beca...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>349</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2_norm</td>\n",
       "      <td>I greatly support the idea.\\nraised in a certa...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raised, in...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raise, in,...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>250</td>\n",
       "      <td>7.314286</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B2_orig  I greatly support the idea. I support it, beca...   \n",
       "1  B2_norm  I greatly support the idea.\\nraised in a certa...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raised, in...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "1  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (greatly, r), (support, v), (the, a),...   \n",
       "1  [(I, p), (greatly, r), (support, v), (the, a),...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raise, in,...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len       MLC  \\\n",
       "0  [(I, p), (greatly, r), (support, v), (the, a),...       349  7.285714   \n",
       "1  [(I, p), (greatly, r), (support, v), (the, a),...       250  7.314286   \n",
       "\n",
       "        CNC  \n",
       "0  0.857143  \n",
       "1  0.800000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge TAASSC data with texts_df\n",
    "\n",
    "texts_df = pd.merge(texts_df, TAASSC, on='text_id')\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical diversity\n",
    "\n",
    "vocD (with lemmas) using functions from [PELITK](https://github.com/ELI-Data-Mining-Group/pelitk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation before calculating\n",
    "\n",
    "punctuation = ['.','!','?',';',':','#','\"',\"'\",'``','`',',','--','-','...',')','(',\"''\"]\n",
    "\n",
    "texts_df['vocD'] = texts_df.toks.apply(lambda row: [x for x in row if x not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "      <th>vocD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B2_orig</td>\n",
       "      <td>I greatly support the idea. I support it, beca...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>349</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>46.781413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2_norm</td>\n",
       "      <td>I greatly support the idea.\\nraised in a certa...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raised, in...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raise, in,...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>250</td>\n",
       "      <td>7.314286</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>43.456769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B2_orig  I greatly support the idea. I support it, beca...   \n",
       "1  B2_norm  I greatly support the idea.\\nraised in a certa...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raised, in...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "1  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (greatly, r), (support, v), (the, a),...   \n",
       "1  [(I, p), (greatly, r), (support, v), (the, a),...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raise, in,...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len       MLC  \\\n",
       "0  [(I, p), (greatly, r), (support, v), (the, a),...       349  7.285714   \n",
       "1  [(I, p), (greatly, r), (support, v), (the, a),...       250  7.314286   \n",
       "\n",
       "        CNC       vocD  \n",
       "0  0.857143  46.781413  \n",
       "1  0.800000  43.456769  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create vocD column\n",
    "\n",
    "texts_df['vocD'] = texts_df.lemmas_NLTK.apply(lex.vocd)\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical sophistication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Guiraud (AG)\n",
    "AG based on lemmas using a frequency list (PSL3) compiled from the PELIC learner corpus (see dissertation section 2.2.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['yesterday', 'yet', 'yogurt', 'you', 'young', 'your', 'yours', 'yourself', 'youth', 'zoo']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in PSL3 list for manual checking of items in texts that are off list\n",
    "\n",
    "f = open(\"../docs/psl3.txt\", \"r\")\n",
    "PSL3 = f.read()\n",
    "PSL3 = sorted(PSL3.split('\\n'))\n",
    "len(PSL3)\n",
    "PSL3[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "      <th>vocD</th>\n",
       "      <th>AG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B2_orig</td>\n",
       "      <td>I greatly support the idea. I support it, beca...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>349</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>46.781413</td>\n",
       "      <td>0.899735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2_norm</td>\n",
       "      <td>I greatly support the idea.\\nraised in a certa...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raised, in...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raise, in,...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>250</td>\n",
       "      <td>7.314286</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>43.456769</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B2_orig  I greatly support the idea. I support it, beca...   \n",
       "1  B2_norm  I greatly support the idea.\\nraised in a certa...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raised, in...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "1  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (greatly, r), (support, v), (the, a),...   \n",
       "1  [(I, p), (greatly, r), (support, v), (the, a),...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raise, in,...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len       MLC  \\\n",
       "0  [(I, p), (greatly, r), (support, v), (the, a),...       349  7.285714   \n",
       "1  [(I, p), (greatly, r), (support, v), (the, a),...       250  7.314286   \n",
       "\n",
       "        CNC       vocD        AG  \n",
       "0  0.857143  46.781413  0.899735  \n",
       "1  0.800000  43.456769  0.937500  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create AG column (punctuation removed)\n",
    "\n",
    "texts_df['AG'] = texts_df.lemmas_NLTK.apply(lambda row: [x for x in row if x not in punctuation]).apply(\n",
    "    lex.adv_guiraud,freq_list = 'PSL3')\n",
    "\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual diversity\n",
    "\n",
    "Analysis using [TAALES](https://www.linguisticanalysistools.org/taales.html). Based on previous research, one metric is the focus: contextual diversity as in Monteiro et al. (2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in TAALES analysis\n",
    "\n",
    "TAALES = pd.read_csv(\"../docs/B2_TAALES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename files to match texts_df\n",
    "\n",
    "TAALES.Filename = TAALES.Filename.map(file_names)\n",
    "TAALES = TAALES.loc[~TAALES.Filename.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>unigram_range</th>\n",
       "      <th>bigram_range</th>\n",
       "      <th>trigram_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2_norm</td>\n",
       "      <td>0.656513</td>\n",
       "      <td>0.171084</td>\n",
       "      <td>0.024246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B2_orig</td>\n",
       "      <td>0.667837</td>\n",
       "      <td>0.164258</td>\n",
       "      <td>0.029408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id  unigram_range  bigram_range  trigram_range\n",
       "1  B2_norm       0.656513      0.171084       0.024246\n",
       "3  B2_orig       0.667837      0.164258       0.029408"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only relevant contextual diversity columns and rename them\n",
    "\n",
    "TAALES = TAALES[['Filename','COCA_Academic_Range_AW','COCA_Academic_Bigram_Range','COCA_Academic_Trigram_Range']]\n",
    "TAALES = TAALES.rename(columns={\"Filename\": \"text_id\",'COCA_Academic_Range_AW':'unigram_range',\n",
    "                                'COCA_Academic_Bigram_Range':'bigram_range',\n",
    "                                'COCA_Academic_Trigram_Range':'trigram_range'})\n",
    "TAALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "      <th>vocD</th>\n",
       "      <th>AG</th>\n",
       "      <th>unigram_range</th>\n",
       "      <th>bigram_range</th>\n",
       "      <th>trigram_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B2_orig</td>\n",
       "      <td>I greatly support the idea. I support it, beca...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>349</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>46.781413</td>\n",
       "      <td>0.899735</td>\n",
       "      <td>0.667837</td>\n",
       "      <td>0.164258</td>\n",
       "      <td>0.029408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2_norm</td>\n",
       "      <td>I greatly support the idea.\\nraised in a certa...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raised, in...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raise, in,...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>250</td>\n",
       "      <td>7.314286</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>43.456769</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.656513</td>\n",
       "      <td>0.171084</td>\n",
       "      <td>0.024246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B2_orig  I greatly support the idea. I support it, beca...   \n",
       "1  B2_norm  I greatly support the idea.\\nraised in a certa...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raised, in...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "1  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (greatly, r), (support, v), (the, a),...   \n",
       "1  [(I, p), (greatly, r), (support, v), (the, a),...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raise, in,...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len       MLC  \\\n",
       "0  [(I, p), (greatly, r), (support, v), (the, a),...       349  7.285714   \n",
       "1  [(I, p), (greatly, r), (support, v), (the, a),...       250  7.314286   \n",
       "\n",
       "        CNC       vocD        AG  unigram_range  bigram_range  trigram_range  \n",
       "0  0.857143  46.781413  0.899735       0.667837      0.164258       0.029408  \n",
       "1  0.800000  43.456769  0.937500       0.656513      0.171084       0.024246  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge TAALES data with texts_df\n",
    "\n",
    "texts_df = pd.merge(texts_df, TAALES, on='text_id')\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocation measures\n",
    "3 measures which make up 'CollGram' profile from Granger & Bestgen / Bestgen & Granger (2014):\n",
    "- mean MI\n",
    "- mean t-score\n",
    "- proportion or bigrams absent from reference corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract potential collocations in span 4\n",
    "\n",
    "def find_cols(lemma_list):\n",
    "    col_list = list(zip(lemma_list,lemma_list[1:]))+list(zip(lemma_list,lemma_list[2:]))\\\n",
    "    +list(zip(lemma_list,lemma_list[3:]))+list(zip(lemma_list,lemma_list[4:]))\n",
    "    return col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create possible collocations column\n",
    "\n",
    "texts_df['possible_cols'] = texts_df.lemmas_CLAWS.apply(find_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower-case (doesn't matter that 'I' gets lowered as not in collocate dict)\n",
    "\n",
    "texts_df['possible_cols'] = texts_df.possible_cols.apply(\n",
    "    lambda row: [((x[0][0].lower(),x[0][1]),(x[1][0].lower(),x[1][1])) for x in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('a', 'a'), ('a', 'a')), (('a', 'a'), ('always', 'r')), (('a', 'a'), ('be', 'v')), (('a', 'a'), ('but', 'c')), (('a', 'a'), ('certain', 'j'))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(('work', 'v'), ('very', 'r')), (('world', 'n'), ('a', 'a')), (('world', 'n'), ('be', 'v')), (('world', 'n'), ('tough', 'j')), (('world', 'n'), ('very', 'r'))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1305"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of all possible collocations\n",
    "\n",
    "possible_cols = sorted(list(set([x for y in texts_df.possible_cols.to_list() for x in y])))\n",
    "possible_cols[:5]\n",
    "possible_cols[-5:]\n",
    "len(possible_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean MI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MI is not calculated for any bigrams with freq less than 5 or MI less than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column with MI for each possible collocation in MI dict\n",
    "\n",
    "texts_df['col_MI'] = texts_df.possible_cols.apply(lambda row: [(x,MI_dict[x]) for x in row if x in MI_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mean MI for each text based on tokens and types\n",
    "\n",
    "texts_df['mean_MI'] = texts_df.col_MI.apply(lambda row: np.mean([x[1] for x in row]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion of absent/low MI word combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column of two-word combinations not in collocation dict\n",
    "\n",
    "texts_df['absent'] = texts_df.possible_cols.apply(lambda row: [x for x in row if x not in col_freq_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find proportion of absent two-word combinations compared to total two-word combinations in the text\n",
    "\n",
    "texts_df['absent_prop'] = texts_df.absent.apply(lambda row: len(row)) / texts_df.possible_cols.apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find proportion of absent two-word combination types compared to total two-word combination types in the text\n",
    "\n",
    "texts_df['absent_prop_types'] = texts_df.absent.apply(lambda row: len(set(row))) / texts_df.possible_cols.apply(lambda row: len(set(row)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean t-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column with t-score for each bigram\n",
    "\n",
    "texts_df['col_tscore'] = texts_df.possible_cols.apply(lambda row: [(x,tscore_dict[x]) for x in row if x in tscore_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mean t-score for each text based on tokens and types\n",
    "\n",
    "texts_df['mean_tscore'] = texts_df.col_tscore.apply(lambda row: np.mean([x[1] for x in row]))\n",
    "texts_df['mean_tscore_types'] = texts_df.col_tscore.apply(lambda row: np.mean([x[1] for x in set(row)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "      <th>vocD</th>\n",
       "      <th>AG</th>\n",
       "      <th>unigram_range</th>\n",
       "      <th>bigram_range</th>\n",
       "      <th>trigram_range</th>\n",
       "      <th>possible_cols</th>\n",
       "      <th>col_MI</th>\n",
       "      <th>mean_MI</th>\n",
       "      <th>absent</th>\n",
       "      <th>absent_prop</th>\n",
       "      <th>absent_prop_types</th>\n",
       "      <th>col_tscore</th>\n",
       "      <th>mean_tscore</th>\n",
       "      <th>mean_tscore_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B2_orig</td>\n",
       "      <td>I greatly support the idea. I support it, beca...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>349</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>46.781413</td>\n",
       "      <td>0.899735</td>\n",
       "      <td>0.667837</td>\n",
       "      <td>0.164258</td>\n",
       "      <td>0.029408</td>\n",
       "      <td>[((i, p), (greatly, r)), ((greatly, r), (suppo...</td>\n",
       "      <td>[((('because', 'i'), ('of', 'i')), 2.29), ((('...</td>\n",
       "      <td>2.940200</td>\n",
       "      <td>[((i, p), (greatly, r)), ((greatly, r), (suppo...</td>\n",
       "      <td>0.964838</td>\n",
       "      <td>0.966216</td>\n",
       "      <td>[((('because', 'i'), ('of', 'i')), 443.825), (...</td>\n",
       "      <td>162.092860</td>\n",
       "      <td>145.610200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2_norm</td>\n",
       "      <td>I greatly support the idea.\\nraised in a certa...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raised, in...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raise, in,...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>250</td>\n",
       "      <td>7.314286</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>43.456769</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.656513</td>\n",
       "      <td>0.171084</td>\n",
       "      <td>0.024246</td>\n",
       "      <td>[((i, p), (greatly, r)), ((greatly, r), (suppo...</td>\n",
       "      <td>[((('such', 'i'), ('as', 'i')), 6.02), ((('har...</td>\n",
       "      <td>2.878056</td>\n",
       "      <td>[((i, p), (greatly, r)), ((greatly, r), (suppo...</td>\n",
       "      <td>0.964497</td>\n",
       "      <td>0.965478</td>\n",
       "      <td>[((('such', 'i'), ('as', 'i')), 494.477), ((('...</td>\n",
       "      <td>153.301056</td>\n",
       "      <td>126.052867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B2_orig  I greatly support the idea. I support it, beca...   \n",
       "1  B2_norm  I greatly support the idea.\\nraised in a certa...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raised, in...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "1  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (greatly, r), (support, v), (the, a),...   \n",
       "1  [(I, p), (greatly, r), (support, v), (the, a),...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raise, in,...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len       MLC  \\\n",
       "0  [(I, p), (greatly, r), (support, v), (the, a),...       349  7.285714   \n",
       "1  [(I, p), (greatly, r), (support, v), (the, a),...       250  7.314286   \n",
       "\n",
       "        CNC       vocD        AG  unigram_range  bigram_range  trigram_range  \\\n",
       "0  0.857143  46.781413  0.899735       0.667837      0.164258       0.029408   \n",
       "1  0.800000  43.456769  0.937500       0.656513      0.171084       0.024246   \n",
       "\n",
       "                                       possible_cols  \\\n",
       "0  [((i, p), (greatly, r)), ((greatly, r), (suppo...   \n",
       "1  [((i, p), (greatly, r)), ((greatly, r), (suppo...   \n",
       "\n",
       "                                              col_MI   mean_MI  \\\n",
       "0  [((('because', 'i'), ('of', 'i')), 2.29), ((('...  2.940200   \n",
       "1  [((('such', 'i'), ('as', 'i')), 6.02), ((('har...  2.878056   \n",
       "\n",
       "                                              absent  absent_prop  \\\n",
       "0  [((i, p), (greatly, r)), ((greatly, r), (suppo...     0.964838   \n",
       "1  [((i, p), (greatly, r)), ((greatly, r), (suppo...     0.964497   \n",
       "\n",
       "   absent_prop_types                                         col_tscore  \\\n",
       "0           0.966216  [((('because', 'i'), ('of', 'i')), 443.825), (...   \n",
       "1           0.965478  [((('such', 'i'), ('as', 'i')), 494.477), ((('...   \n",
       "\n",
       "   mean_tscore  mean_tscore_types  \n",
       "0   162.092860         145.610200  \n",
       "1   153.301056         126.052867  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "Grammatical accuracy and collocational accuracy. Errors manually annotated and counted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grammatical accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create lists of manually identified errors\n",
    "\n",
    "B2_orig_grammar = ['are raise','oppose to it','is used to have','is easily gave','watched their parent every day worked','have work hard','they bought (buy)','children needs',\"so doesn't (don't')\",'to discovered']\n",
    "B2_norm_grammar = ['is used to have','is easily gave','watched their parent every day worked','have work hard','they bought (buy)',\"so doesn't (don't')\",'to discovered']\n",
    "\n",
    "len(B2_orig_grammar)\n",
    "len(B2_norm_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grammatical accuracy column\n",
    "\n",
    "grammar_dict = {'B2_orig':len(B2_orig_grammar),'B2_norm':len(B2_norm_grammar)}\n",
    "\n",
    "texts_df['grammar_errors'] = texts_df.text_id.map(grammar_dict)\n",
    "texts_df['grammar_errors_per_100'] = (texts_df.grammar_errors/texts_df.text_len)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add punctuation column (manually counted)\n",
    "\n",
    "punc_dict = {'B2_orig':9,'B2_norm':6}\n",
    "\n",
    "texts_df['punc_errors'] = texts_df.text_id.map(punc_dict)\n",
    "texts_df['punc_errors_per_100'] = (texts_df.punc_errors/texts_df.text_len)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocational accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Record of collocation errors. MI calculations not comparable with two and three word collocations.\n",
    "\n",
    "B2_orig_errors = ['raise in (values)','psychological values','oppose to it','is easily gave','well-trained to face adulthood','put food in the table','set their mind that','family love life','express love by money','impact to','adult life problems']\n",
    "B2_norm_errors = ['raised in (values)','psychological values','oppose to it','well-trained to face adulthood','put food in the table','set their mind that','express love by money','impact to']\n",
    "\n",
    "len(B2_orig_errors)\n",
    "len(B2_norm_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accurate collocations (manually annotated)\n",
    "\n",
    "B2_orig_cols = ['support the idea','value of hard work','in the condition','come easily','comes from a wealthy family','have money','worked very hard','have the advantage','see the reality (and embrace it)','blinded by','power of money','expensive clothes','are never home','source of happiness','all the time','the art of','On the contrary','grow up with','sense of respect','have a disadvantage','have the time to','face problems','the following reason','work for it','see the fact','tough place','authentic self','love their children','basic necessity','care about','use it well']\n",
    "B2_norm_cols = ['support the idea','value of hard work','in the condition','come easily','comes from a wealthy family','have money','worked very hard','have the advantage','see the reality (and embrace it)','blinded by','power of money','expensive clothes','are never home','source of happiness','all the time','the art of','On the contrary','grow up with','sense of respect','have a disadvantage','have the time to','face problems']\n",
    "\n",
    "len(B2_orig_cols)\n",
    "len(B2_norm_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'bad' cols column for future use\n",
    "\n",
    "texts_df['bad_cols'] = (B2_orig_errors,B2_norm_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create error and accurate cols columns\n",
    "\n",
    "errors_dict = {'B2_orig':len(B2_orig_errors),'B2_norm':len(B2_norm_errors)}\n",
    "correct_dict = {'B2_orig':len(B2_orig_cols),'B2_norm':len(B2_norm_cols)}\n",
    "\n",
    "texts_df['col_errors'] = texts_df.text_id.map(errors_dict)\n",
    "texts_df['correct_cols'] = texts_df.text_id.map(correct_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create errors and correct cols per 100 words columns\n",
    "\n",
    "texts_df['col_errors_per_100'] = (texts_df.col_errors/texts_df.text_len)*100\n",
    "texts_df['correct_cols_per_100'] = (texts_df.correct_cols/texts_df.text_len)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocation frequency bands\n",
    "Percentage of collocations containing low/mid/high freq items.  \n",
    "- High = K1-2\n",
    "- Mid = K3-9\n",
    "- Low = K10+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize collocations\n",
    "\n",
    "B2_orig_cols_toks = [x.split() for x in B2_orig_cols]\n",
    "B2_norm_cols_toks = [x.split() for x in B2_norm_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['support', 'the', 'idea'], ['value', 'of', 'hard', 'work'], ['in', 'the', 'condition'], ['come', 'easily'], ['comes', 'from', 'a', 'wealthy', 'family'], ['have', 'money'], ['worked', 'very', 'hard'], ['have', 'the', 'advantage'], ['see', 'the', 'reality', '(and', 'embrace', 'it)'], ['blinded', 'by'], ['power', 'of', 'money'], ['expensive', 'clothes'], ['are', 'never', 'home'], ['source', 'of', 'happiness'], ['all', 'the', 'time'], ['the', 'art', 'of'], ['On', 'the', 'contrary'], ['grow', 'up', 'with'], ['sense', 'of', 'respect'], ['have', 'a', 'disadvantage'], ['have', 'the', 'time', 'to'], ['face', 'problems'], ['the', 'following', 'reason'], ['work', 'for', 'it'], ['see', 'the', 'fact'], ['tough', 'place'], ['authentic', 'self'], ['love', 'their', 'children'], ['basic', 'necessity'], ['care', 'about'], ['use', 'it', 'well']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[['support', 'the', 'idea'], ['value', 'of', 'hard', 'work'], ['in', 'the', 'condition'], ['come', 'easily'], ['comes', 'from', 'a', 'wealthy', 'family'], ['have', 'money'], ['worked', 'very', 'hard'], ['have', 'the', 'advantage'], ['see', 'the', 'reality', '(and', 'embrace', 'it)'], ['blinded', 'by'], ['power', 'of', 'money'], ['expensive', 'clothes'], ['are', 'never', 'home'], ['source', 'of', 'happiness'], ['all', 'the', 'time'], ['the', 'art', 'of'], ['On', 'the', 'contrary'], ['grow', 'up', 'with'], ['sense', 'of', 'respect'], ['have', 'a', 'disadvantage'], ['have', 'the', 'time', 'to'], ['face', 'problems']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B2_orig_cols_toks\n",
    "B2_norm_cols_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collocations with PoS (manually lemmatized and tagged based on above)\n",
    "\n",
    "B2_orig_cols_toks_POS = [[('support','v'),('the','a'),('idea','n')],\n",
    "                         [('value','n'),('of','i'),('hard','j'),('work','n')],\n",
    "                         [('in','i'), ('the','a'), ('condition','n')],\n",
    "                         [('come','v'), ('easily','r')],\n",
    "                         [('come','v'), ('from','i'), ('a','a'), ('wealthy','j'), ('family','n')],\n",
    "                         [('have','v'), ('money','n')],\n",
    "                         [('work','v'), ('very','r'), ('hard','r')],\n",
    "                         [('have','v'), ('the','a'), ('advantage','n')],\n",
    "                         [('see','v'), ('the','a'), ('reality','n'),('and','c'), ('embrace','v'), ('it','p')],\n",
    "                         [('blind','v'), ('by','i')],\n",
    "                         [('power','n'), ('of','i'), ('money','n')],\n",
    "                         [('expensive','j'), ('clothes','n')],\n",
    "                         [('be','v'), ('never','r'), ('home','r')],\n",
    "                         [('source','n'), ('of','i'), ('happiness','n')],\n",
    "                         [('all','d'), ('the','a'), ('time','n')],\n",
    "                         [('the','a'), ('art','n'), ('of','i')],\n",
    "                         [('on','i'), ('the','a'), ('contrary','n')],\n",
    "                         [('grow','v'), ('up','r'), ('with','i')],\n",
    "                         [('sense','n'), ('of','i'), ('respect','n')],\n",
    "                         [('have','v'), ('a','a'), ('disadvantage','n')],\n",
    "                         [('have','v'), ('the','a'), ('time','n'), ('to','t')],\n",
    "                         [('face','v'), ('problem','n')],\n",
    "                         [('the','a'), ('following','j'), ('reason','n')],\n",
    "                         [('work','v'), ('for','i'), ('it','p')],\n",
    "                         [('see','v'), ('the','a'), ('fact','n')],\n",
    "                         [('tough','j'), ('place','n')],\n",
    "                         [('authentic','j'), ('self','n')],\n",
    "                         [('love','v'), ('their','a'), ('child','n')],\n",
    "                         [('basic','j'), ('necessity','n')],\n",
    "                         [('care','v'), ('about','i')],\n",
    "                         [('use','v'), ('it','p'), ('well','r')]]\n",
    "\n",
    "B2_norm_cols_toks_POS =  [[('support','v'),('the','a'),('idea','n')],\n",
    "                         [('value','n'),('of','i'),('hard','j'),('work','n')],\n",
    "                         [('in','i'), ('the','a'), ('condition','n')],\n",
    "                         [('come','v'), ('easily','r')],\n",
    "                         [('come','v'), ('from','i'), ('a','a'), ('wealthy','j'), ('family','n')],\n",
    "                         [('have','v'), ('money','n')],\n",
    "                         [('work','v'), ('very','r'), ('hard','r')],\n",
    "                         [('have','v'), ('the','a'), ('advantage','n')],\n",
    "                         [('see','v'), ('the','a'), ('reality','n'),('and','c'), ('embrace','v'), ('it','p')],\n",
    "                         [('blind','v'), ('by','i')],\n",
    "                         [('power','n'), ('of','i'), ('money','n')],\n",
    "                         [('expensive','j'), ('clothes','n')],\n",
    "                         [('be','v'), ('never','r'), ('home','r')],\n",
    "                         [('source','n'), ('of','i'), ('happiness','n')],\n",
    "                         [('all','d'), ('the','a'), ('time','n')],\n",
    "                         [('the','a'), ('art','n'), ('of','i')],\n",
    "                         [('on','i'), ('the','a'), ('contrary','n')],\n",
    "                         [('grow','v'), ('up','r'), ('with','i')],\n",
    "                         [('sense','n'), ('of','i'), ('respect','n')],\n",
    "                         [('have','v'), ('a','a'), ('disadvantage','n')],\n",
    "                         [('have','v'), ('the','a'),('time','n'), ('to','t')],\n",
    "                         [('face','v'), ('problem','n')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create collocation dict\n",
    "\n",
    "col_dict = {'B2_orig':B2_orig_cols_toks_POS,'B2_norm':B2_norm_cols_toks_POS}\n",
    "\n",
    "# Create column with collocations\n",
    "\n",
    "texts_df['cols'] = texts_df.text_id.map(col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column of the freq bands of the highest kband item in each collocation\n",
    "\n",
    "texts_df['col_kband'] = texts_df.cols.apply(\n",
    "    lambda row:[sorted([kband_dict[y] for y in x],reverse=True)[0] for x in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create (kband, cols) tuples\n",
    "\n",
    "texts_df['kband_cols'] = list(zip(texts_df.col_kband,texts_df.cols))\n",
    "texts_df['kband_cols'] = texts_df['kband_cols'].apply(lambda row: list(zip(row[0],row[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Kbands\n",
    "\n",
    "high_freq_K = list(range(1,3))\n",
    "mid_freq_K = list(range(3,10))\n",
    "low_freq_K = list(range(10,101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns of percentages of cols that contain low, med, high kband items (highest only)\n",
    "\n",
    "texts_df['K10to16_cols'] = texts_df.col_kband.apply(lambda row: len([x for x in row if x in(low_freq_K)]))\n",
    "texts_df['K3to9_cols'] = texts_df.col_kband.apply(lambda row: len([x for x in row if x in(mid_freq_K)]))\n",
    "texts_df['K1to2_cols'] = texts_df.col_kband.apply(lambda row: len([x for x in row if x in(high_freq_K)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add percent columns\n",
    "\n",
    "texts_df['K10to16_p'] = texts_df['K10to16_cols']/(texts_df['K10to16_cols']+texts_df['K3to9_cols']+texts_df['K1to2_cols'])\n",
    "texts_df['K3to9_p'] = texts_df['K3to9_cols']/(texts_df['K10to16_cols']+texts_df['K3to9_cols']+texts_df['K1to2_cols'])\n",
    "texts_df['K1to2_p'] = texts_df['K1to2_cols']/(texts_df['K10to16_cols']+texts_df['K3to9_cols']+texts_df['K1to2_cols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate columns with low/mid/high cols for ease of viewing\n",
    "\n",
    "texts_df['K1to2_cols_K'] = texts_df.kband_cols.apply(lambda row: [x for x in row if x[0] <= 2])\n",
    "texts_df['K3to9_cols_K'] = texts_df.kband_cols.apply(lambda row: [x for x in row if 10 > x[0] > 2])\n",
    "texts_df['K10to16_cols_K'] = texts_df.kband_cols.apply(lambda row: [x for x in row if x[0] > 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "      <th>vocD</th>\n",
       "      <th>AG</th>\n",
       "      <th>unigram_range</th>\n",
       "      <th>bigram_range</th>\n",
       "      <th>trigram_range</th>\n",
       "      <th>possible_cols</th>\n",
       "      <th>col_MI</th>\n",
       "      <th>mean_MI</th>\n",
       "      <th>absent</th>\n",
       "      <th>absent_prop</th>\n",
       "      <th>absent_prop_types</th>\n",
       "      <th>col_tscore</th>\n",
       "      <th>mean_tscore</th>\n",
       "      <th>mean_tscore_types</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>grammar_errors_per_100</th>\n",
       "      <th>punc_errors</th>\n",
       "      <th>punc_errors_per_100</th>\n",
       "      <th>bad_cols</th>\n",
       "      <th>col_errors</th>\n",
       "      <th>correct_cols</th>\n",
       "      <th>col_errors_per_100</th>\n",
       "      <th>correct_cols_per_100</th>\n",
       "      <th>cols</th>\n",
       "      <th>col_kband</th>\n",
       "      <th>kband_cols</th>\n",
       "      <th>K10to16_cols</th>\n",
       "      <th>K3to9_cols</th>\n",
       "      <th>K1to2_cols</th>\n",
       "      <th>K10to16_p</th>\n",
       "      <th>K3to9_p</th>\n",
       "      <th>K1to2_p</th>\n",
       "      <th>K1to2_cols_K</th>\n",
       "      <th>K3to9_cols_K</th>\n",
       "      <th>K10to16_cols_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B2_orig</td>\n",
       "      <td>I greatly support the idea. I support it, beca...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., I, support...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>349</td>\n",
       "      <td>7.286</td>\n",
       "      <td>0.857</td>\n",
       "      <td>46.781</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.029</td>\n",
       "      <td>[((i, p), (greatly, r)), ((greatly, r), (suppo...</td>\n",
       "      <td>[((('because', 'i'), ('of', 'i')), 2.29), ((('...</td>\n",
       "      <td>2.940</td>\n",
       "      <td>[((i, p), (greatly, r)), ((greatly, r), (suppo...</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.966</td>\n",
       "      <td>[((('because', 'i'), ('of', 'i')), 443.825), (...</td>\n",
       "      <td>162.093</td>\n",
       "      <td>145.610</td>\n",
       "      <td>10</td>\n",
       "      <td>2.865</td>\n",
       "      <td>9</td>\n",
       "      <td>2.579</td>\n",
       "      <td>[raise in (values), psychological values, oppo...</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>3.152</td>\n",
       "      <td>8.883</td>\n",
       "      <td>[[(support, v), (the, a), (idea, n)], [(value,...</td>\n",
       "      <td>[1, 1, 1, 2, 3, 1, 1, 2, 3, 8, 1, 2, 1, 4, 1, ...</td>\n",
       "      <td>[(1, [('support', 'v'), ('the', 'a'), ('idea',...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.742</td>\n",
       "      <td>[(1, [('support', 'v'), ('the', 'a'), ('idea',...</td>\n",
       "      <td>[(3, [('come', 'v'), ('from', 'i'), ('a', 'a')...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2_norm</td>\n",
       "      <td>I greatly support the idea.\\nraised in a certa...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raised, in...</td>\n",
       "      <td>[(I, PRP), (greatly, RB), (support, VBP), (the...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>[I, greatly, support, the, idea, ., raise, in,...</td>\n",
       "      <td>[(I, p), (greatly, r), (support, v), (the, a),...</td>\n",
       "      <td>250</td>\n",
       "      <td>7.314</td>\n",
       "      <td>0.800</td>\n",
       "      <td>43.457</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.024</td>\n",
       "      <td>[((i, p), (greatly, r)), ((greatly, r), (suppo...</td>\n",
       "      <td>[((('such', 'i'), ('as', 'i')), 6.02), ((('har...</td>\n",
       "      <td>2.878</td>\n",
       "      <td>[((i, p), (greatly, r)), ((greatly, r), (suppo...</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.965</td>\n",
       "      <td>[((('such', 'i'), ('as', 'i')), 494.477), ((('...</td>\n",
       "      <td>153.301</td>\n",
       "      <td>126.053</td>\n",
       "      <td>7</td>\n",
       "      <td>2.800</td>\n",
       "      <td>6</td>\n",
       "      <td>2.400</td>\n",
       "      <td>[raised in (values), psychological values, opp...</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>3.200</td>\n",
       "      <td>8.800</td>\n",
       "      <td>[[(support, v), (the, a), (idea, n)], [(value,...</td>\n",
       "      <td>[1, 1, 1, 2, 3, 1, 1, 2, 3, 8, 1, 2, 1, 4, 1, ...</td>\n",
       "      <td>[(1, [('support', 'v'), ('the', 'a'), ('idea',...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.727</td>\n",
       "      <td>[(1, [('support', 'v'), ('the', 'a'), ('idea',...</td>\n",
       "      <td>[(3, [('come', 'v'), ('from', 'i'), ('a', 'a')...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B2_orig  I greatly support the idea. I support it, beca...   \n",
       "1  B2_norm  I greatly support the idea.\\nraised in a certa...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raised, in...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "1  [(I, PRP), (greatly, RB), (support, VBP), (the...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (greatly, r), (support, v), (the, a),...   \n",
       "1  [(I, p), (greatly, r), (support, v), (the, a),...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, greatly, support, the, idea, ., I, support...   \n",
       "1  [I, greatly, support, the, idea, ., raise, in,...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len    MLC    CNC  \\\n",
       "0  [(I, p), (greatly, r), (support, v), (the, a),...       349  7.286  0.857   \n",
       "1  [(I, p), (greatly, r), (support, v), (the, a),...       250  7.314  0.800   \n",
       "\n",
       "     vocD     AG  unigram_range  bigram_range  trigram_range  \\\n",
       "0  46.781  0.900          0.668         0.164          0.029   \n",
       "1  43.457  0.938          0.657         0.171          0.024   \n",
       "\n",
       "                                       possible_cols  \\\n",
       "0  [((i, p), (greatly, r)), ((greatly, r), (suppo...   \n",
       "1  [((i, p), (greatly, r)), ((greatly, r), (suppo...   \n",
       "\n",
       "                                              col_MI  mean_MI  \\\n",
       "0  [((('because', 'i'), ('of', 'i')), 2.29), ((('...    2.940   \n",
       "1  [((('such', 'i'), ('as', 'i')), 6.02), ((('har...    2.878   \n",
       "\n",
       "                                              absent  absent_prop  \\\n",
       "0  [((i, p), (greatly, r)), ((greatly, r), (suppo...        0.965   \n",
       "1  [((i, p), (greatly, r)), ((greatly, r), (suppo...        0.964   \n",
       "\n",
       "   absent_prop_types                                         col_tscore  \\\n",
       "0              0.966  [((('because', 'i'), ('of', 'i')), 443.825), (...   \n",
       "1              0.965  [((('such', 'i'), ('as', 'i')), 494.477), ((('...   \n",
       "\n",
       "   mean_tscore  mean_tscore_types  grammar_errors  grammar_errors_per_100  \\\n",
       "0      162.093            145.610              10                   2.865   \n",
       "1      153.301            126.053               7                   2.800   \n",
       "\n",
       "   punc_errors  punc_errors_per_100  \\\n",
       "0            9                2.579   \n",
       "1            6                2.400   \n",
       "\n",
       "                                            bad_cols  col_errors  \\\n",
       "0  [raise in (values), psychological values, oppo...          11   \n",
       "1  [raised in (values), psychological values, opp...           8   \n",
       "\n",
       "   correct_cols  col_errors_per_100  correct_cols_per_100  \\\n",
       "0            31               3.152                 8.883   \n",
       "1            22               3.200                 8.800   \n",
       "\n",
       "                                                cols  \\\n",
       "0  [[(support, v), (the, a), (idea, n)], [(value,...   \n",
       "1  [[(support, v), (the, a), (idea, n)], [(value,...   \n",
       "\n",
       "                                           col_kband  \\\n",
       "0  [1, 1, 1, 2, 3, 1, 1, 2, 3, 8, 1, 2, 1, 4, 1, ...   \n",
       "1  [1, 1, 1, 2, 3, 1, 1, 2, 3, 8, 1, 2, 1, 4, 1, ...   \n",
       "\n",
       "                                          kband_cols  K10to16_cols  \\\n",
       "0  [(1, [('support', 'v'), ('the', 'a'), ('idea',...             0   \n",
       "1  [(1, [('support', 'v'), ('the', 'a'), ('idea',...             0   \n",
       "\n",
       "   K3to9_cols  K1to2_cols  K10to16_p  K3to9_p  K1to2_p  \\\n",
       "0           8          23        0.0    0.258    0.742   \n",
       "1           6          16        0.0    0.273    0.727   \n",
       "\n",
       "                                        K1to2_cols_K  \\\n",
       "0  [(1, [('support', 'v'), ('the', 'a'), ('idea',...   \n",
       "1  [(1, [('support', 'v'), ('the', 'a'), ('idea',...   \n",
       "\n",
       "                                        K3to9_cols_K K10to16_cols_K  \n",
       "0  [(3, [('come', 'v'), ('from', 'i'), ('a', 'a')...             []  \n",
       "1  [(3, [('come', 'v'), ('from', 'i'), ('a', 'a')...             []  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round all stats to 3 digits for ease of use\n",
    "\n",
    "texts_df = round(texts_df,3)\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing length\n",
    "\n",
    "Results of comparison between original and normalized versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function for finding range of + or - 5%\n",
    "\n",
    "def find_range(stat):\n",
    "    low = str(round(stat*.95,2))\n",
    "    high = str(round(stat*1.05,2))\n",
    "    stat_range = low + ' - ' + high\n",
    "    return stat_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46.781, 43.457]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'44.44 - 49.12'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocD: mod within 5% of orig (remember that changes slightly every time calculated as based on samples)\n",
    "\n",
    "B2_vocd = texts_df['vocD'].to_list()\n",
    "B2_vocd \n",
    "\n",
    "find_range(B2_vocd[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9, 0.938]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.85 - 0.95'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AG (PSL): mod within 5% of orig\n",
    "\n",
    "B2_AG = texts_df['AG'].to_list()\n",
    "B2_AG\n",
    "\n",
    "find_range(B2_AG[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.94, 2.878]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'2.79 - 3.09'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean MI (words): mod within 5% of orig\n",
    "\n",
    "B2_mean_MI = texts_df['mean_MI'].to_list()\n",
    "B2_mean_MI\n",
    "\n",
    "find_range(B2_mean_MI[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[162.093, 153.301]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'153.99 - 170.2'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean t-score (words): mod within 5% of orig\n",
    "\n",
    "B2_mean_t_score = texts_df['mean_tscore'].to_list()\n",
    "B2_mean_t_score\n",
    "\n",
    "find_range(B2_mean_t_score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.965, 0.964]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.92 - 1.01'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean proportion of bigrams (words): mod within 5% of orig or closest possible (see B2)\n",
    "\n",
    "B2_absent_prop = texts_df['absent_prop'].to_list()\n",
    "B2_absent_prop\n",
    "\n",
    "find_range(B2_absent_prop[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.865, 2.8]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'2.72 - 3.01'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grammar errors per 100: mod within 5% of orig\n",
    "\n",
    "B2_grammar_errors_per_100 = texts_df['grammar_errors_per_100'].to_list()\n",
    "B2_grammar_errors_per_100\n",
    "\n",
    "find_range(B2_grammar_errors_per_100[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.579, 2.4]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'2.45 - 2.71'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Punctuation errors per 100: mod within 5% of orig\n",
    "\n",
    "B2_punc_errors_per_100 = texts_df['punc_errors_per_100'].to_list()\n",
    "B2_punc_errors_per_100\n",
    "\n",
    "find_range(B2_punc_errors_per_100[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.152, 3.2]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'2.99 - 3.31'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collocation errors per 100: mod within 5% of orig\n",
    "\n",
    "B2_col_errors_per_100 = texts_df['col_errors_per_100'].to_list()\n",
    "B2_col_errors_per_100\n",
    "\n",
    "find_range(B2_col_errors_per_100[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.883, 8.8]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'8.44 - 9.33'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accurate colls per 100\n",
    "\n",
    "B2_correct_cols_per_100 = texts_df['correct_cols_per_100'].to_list()\n",
    "B2_correct_cols_per_100\n",
    "\n",
    "find_range(B2_correct_cols_per_100[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.0 - 0.0'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K10-16 cols percent\n",
    "\n",
    "B2_K10to16_p = texts_df['K10to16_p'].to_list()\n",
    "B2_K10to16_p\n",
    "\n",
    "find_range(B2_K10to16_p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.258, 0.273]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.25 - 0.27'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K3-9 cols percent\n",
    "\n",
    "B2_K3to9_p = texts_df['K3to9_p'].to_list()\n",
    "B2_K3to9_p\n",
    "\n",
    "find_range(B2_K3to9_p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.742, 0.727]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.7 - 0.78'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K1-2 cols percent\n",
    "\n",
    "B2_K1to2_p = texts_df['K1to2_p'].to_list()\n",
    "B2_K1to2_p\n",
    "\n",
    "find_range(B2_K1to2_p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.164, 0.171]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.16 - 0.17'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bigram range: mod within 5% of orig\n",
    "\n",
    "B2_bigram_range = texts_df['bigram_range'].to_list()\n",
    "B2_bigram_range\n",
    "\n",
    "find_range(B2_bigram_range[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.857, 0.8]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.81 - 0.9'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNC: mod within 5% of orig\n",
    "\n",
    "B2_CNC = texts_df['CNC'].to_list()\n",
    "B2_CNC\n",
    "\n",
    "find_range(B2_CNC[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.286, 7.314]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'6.92 - 7.65'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLC: mod within 5% of orig\n",
    "\n",
    "B2_MLC = texts_df['MLC'].to_list()\n",
    "B2_MLC\n",
    "\n",
    "find_range(B2_MLC[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison with relevant stats only\n",
    "\n",
    "texts_final = texts_df[['text_id','text','lemmas_NLTK','lemmas_CLAWS','text_len','MLC','CNC','grammar_errors_per_100',\n",
    "                        'punc_errors_per_100','vocD','AG','bigram_range','mean_MI','absent_prop',\n",
    "                        'mean_tscore','col_errors_per_100','correct_cols_per_100','K10to16_p','K3to9_p','K1to2_p',\n",
    "                        'kband_cols', 'K1to2_cols','K3to9_cols','K10to16_cols',\n",
    "                        'K1to2_cols_K','K3to9_cols_K','K10to16_cols_K','bad_cols']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../docs/B2_orig&norm.pkl']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pickle for later use\n",
    "\n",
    "joblib.dump(texts_final ,'../docs/B2_orig&norm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../docs/B2_cols.pkl']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pickle possible cols for collocation identification notebook\n",
    "\n",
    "B2_cols = texts_df[['text_id','lemmas_CLAWS','possible_cols']]\n",
    "\n",
    "joblib.dump(B2_cols ,'../docs/B2_cols.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Normalizing-B1-original-text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
