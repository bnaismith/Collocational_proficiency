{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing B1 original text\n",
    "\n",
    "<br>\n",
    "\n",
    "**Language: Python**\n",
    "\n",
    "This notebook shows the process used for creating the length-normalized B1 text from the original public IELTS Task 2 B1 text. The original text is a public academic writing sample from the [IELTS website](https://www.ielts.org/en-us/about-the-test/sample-test-questions). The original text is 172 words and the desired length is 250 words (see chapters 5.1 and 5.2 of the dissertation).\n",
    "\n",
    "**Notebook contents:**\n",
    "- [Initial setup](#Initial-setup)\n",
    "- [Text processing](#Text-processing)\n",
    "- [Syntactic complexity](#Syntactic-complexity)\n",
    "- [Lexical diversity](#Lexical-diversity)\n",
    "- [Lexical sophistication](#Lexical-sophistication)\n",
    "- [Collocation measures](#Collocation-measures)\n",
    "- [Accuracy](#Accuracy)\n",
    "- [Normalizing length](#Normalizing-length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import csv\n",
    "from ast import literal_eval\n",
    "from nltk import pos_tag_sents\n",
    "from pelitk import lex\n",
    "import joblib\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "# Set preferred notebook format\n",
    "\n",
    "%pprint # Turn off pretty printing\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # Show all output, not just last item\n",
    "pd.set_option('display.max_columns', 999) # Allow viewing of all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** As described in the [README.md]('../README.md'), The frequency information from COCA referenced here is not freely available but can be purchased at https://corpus.byu.edu/coca. Without this data you will be able to see a few rows of these dataframes, but will not be able to run the code yourself. The t-scores and K-bands were also calculated using these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary dictionaries\n",
    "\n",
    "coca_freq_dict = joblib.load('../../COCA_data/COCA_2020_lemma_freq_dict.pkl')\n",
    "coca_word_lemma_dict = joblib.load('../../COCA_data/COCA_2020_word_lemma_dict.pkl')\n",
    "col_freq_dict = joblib.load('../../COCA_data/COCA_2020_collocate_freq_dict.pkl')\n",
    "MI_dict = joblib.load('../../COCA_data/COCA_2020_MI_dict.pkl')\n",
    "tscore_dict = joblib.load('../../COCA_data/COCA_2020_tscore_dict.pkl')\n",
    "kband_dict = joblib.load('../../COCA_data/COCA_2020_lemma_Kband_dict.pkl') # All items lower-case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in original text (transcribed and with corrected spelling)\n",
    "\n",
    "f = open(\"../docs/B1_original_corrected.txt\", \"r\")\n",
    "B1_orig = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In addition to correcting spelling, contractions were changed to full words, '&' to 'and', '20' to 'twenty', and 'Mr' to 'Mister'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in modified text\n",
    "\n",
    "f = open(\"../docs/B1_normalized.txt\", \"r\")\n",
    "B1_norm = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** These modified texts were modified based on the [`Normalizing length`](#Normalizing-length) goals described later, but are incorporated here to avoid having to go through the text processing procedure twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1_orig</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1_norm</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text\n",
       "0  B1_orig  I disagree that point about children brought u...\n",
       "1  B1_norm  I disagree that point about children brought u..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe\n",
    "\n",
    "texts_df = pd.DataFrame({'text_id':pd.Series(['B1_orig','B1_norm']),\n",
    "                         'text':pd.Series([B1_orig,B1_norm])})\n",
    "\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing\n",
    "\n",
    "The tokenizer, part-of-speech tagger, and lemmatizer tools are the same ones used in the creation of the [PELIC](https://github.com/ELI-Data-Mining-Group/PELIC-dataset) corpus. The tokenizer and lemmatizer are not open access but are based on the ones from [NLTK](https://www.nltk.org/), and using the public NLTK tools will yield similar results. For a more detailed description of the modified tools, please see [Naismith et al. (2022)](https://benjamins.com/catalog/ijlcr.21002.nai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Ben/Documents/ELI_Data_Mining/Data-Archive/elitools\n"
     ]
    }
   ],
   "source": [
    "# Change to working directory containing elitools\n",
    "\n",
    "%cd '../../ELI_Data_Mining/Data-Archive/elitools/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lemmatizer\n",
    "\n",
    "%run -i 'lemmatizer_class.py'\n",
    "lemmatizer = lemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer module\n",
    "\n",
    "%run -i 'tokenizer.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Ben/Documents/Collocational_proficiency_Naismith_2022/notebooks\n"
     ]
    }
   ],
   "source": [
    "# Return to previous working directory\n",
    "\n",
    "%cd '../../../Collocational_proficiency_Naismith_2022/notebooks'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1_orig</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1_norm</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B1_orig  I disagree that point about children brought u...   \n",
       "1  B1_norm  I disagree that point about children brought u...   \n",
       "\n",
       "                                                toks  \n",
       "0  [I, disagree, that, point, about, children, br...  \n",
       "1  [I, disagree, that, point, about, children, br...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize text (nltk-based)\n",
    "\n",
    "texts_df['toks'] = texts_df.text.apply(tokenize)\n",
    "\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tagging\n",
    "- NLTK (PELIC)\n",
    "- CLAWS7 (COCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK\n",
    "As there are only three texts (each with three versions), to avoid any errors, I have used the default NLTK tagger (Penn Treebank tagset), then manually checked and corrected the tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply nltk tagger to create series\n",
    "\n",
    "B1_NLTK = pd.Series(pos_tag_sents(texts_df['toks']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-ea1a8cbc1134>:7: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  B1_NLTK_CHECKED = pd.read_csv(\"../docs/B1_NLTK_CHECKED.csv\", header=None, squeeze = True)\n"
     ]
    }
   ],
   "source": [
    "# Check tags\n",
    "\n",
    "# Write out tagged texts\n",
    "B1_NLTK.to_csv('../docs/B1_NLTK.csv', index=False, header=False) \n",
    "\n",
    "# Read in the checked tagged texts as a series\n",
    "B1_NLTK_CHECKED = pd.read_csv(\"../docs/B1_NLTK_CHECKED.csv\", header=None, squeeze = True) \n",
    "B1_NLTK_CHECKED = [literal_eval(x) for x in B1_NLTK_CHECKED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1_orig</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1_norm</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B1_orig  I disagree that point about children brought u...   \n",
       "1  B1_norm  I disagree that point about children brought u...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, disagree, that, point, about, children, br...   \n",
       "1  [I, disagree, that, point, about, children, br...   \n",
       "\n",
       "                                        tok_POS_NLTK  \n",
       "0  [(I, PRP), (disagree, VBP), (that, IN), (point...  \n",
       "1  [(I, PRP), (disagree, VBP), (that, IN), (point...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create column based on checked tagged texts\n",
    "\n",
    "texts_df['tok_POS_NLTK'] = B1_NLTK_CHECKED\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLAWS7\n",
    "\n",
    "By also tagging with CLAWS7, it is easier to match the POS to the COCA info, rather than the Penn tagset used by NLTK and then having to convert.\n",
    "\n",
    "Free CLAWS tagger: http://ucrel-api.lancaster.ac.uk/claws/free.html\n",
    "\n",
    "Again, these tagged texts should be manually checked prior to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in tagged CLAWS texts\n",
    "\n",
    "f = open(\"../docs/B1_original_CLAWS.txt\", \"r\")\n",
    "B1_orig_CLAWS = f.read()\n",
    "\n",
    "f = open(\"../docs/B1_normalized_CLAWS.txt\", \"r\")\n",
    "B1_norm_CLAWS = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove new line characters, split on whitespace, and remove identifier at end\n",
    "\n",
    "B1_orig_CLAWS = B1_orig_CLAWS.replace('\\n', '').split(' ')[:-2]\n",
    "B1_norm_CLAWS = B1_norm_CLAWS.replace('\\n', '').split(' ')[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change tags into tuples\n",
    "\n",
    "B1_orig_CLAWS = [tuple(x.split('_')) for x in B1_orig_CLAWS]\n",
    "B1_norm_CLAWS = [tuple(x.split('_')) for x in B1_norm_CLAWS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1_orig</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, PPIS1), (disagree, VV0), (that, DD1), (po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1_norm</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, PPIS1), (disagree, VV0), (that, DD1), (po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B1_orig  I disagree that point about children brought u...   \n",
       "1  B1_norm  I disagree that point about children brought u...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, disagree, that, point, about, children, br...   \n",
       "1  [I, disagree, that, point, about, children, br...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "1  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \n",
       "0  [(I, PPIS1), (disagree, VV0), (that, DD1), (po...  \n",
       "1  [(I, PPIS1), (disagree, VV0), (that, DD1), (po...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df['toks_POS_CLAWS'] = pd.Series([B1_orig_CLAWS,B1_norm_CLAWS])\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1_orig</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, PPIS1), (disagree, VV0), (that, DD1), (po...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1_norm</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, PPIS1), (disagree, VV0), (that, DD1), (po...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B1_orig  I disagree that point about children brought u...   \n",
       "1  B1_norm  I disagree that point about children brought u...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, disagree, that, point, about, children, br...   \n",
       "1  [I, disagree, that, point, about, children, br...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "1  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, PPIS1), (disagree, VV0), (that, DD1), (po...   \n",
       "1  [(I, PPIS1), (disagree, VV0), (that, DD1), (po...   \n",
       "\n",
       "                                         lemmas_NLTK  \n",
       "0  [I, disagree, that, point, about, child, bring...  \n",
       "1  [I, disagree, that, point, about, child, bring...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create lemmatized text column using our lemmatizer loaded earlier\n",
    "\n",
    "texts_df['lemmas_NLTK'] = texts_df['tok_POS_NLTK'].apply(lemmatizer.lemmatize_text)\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLAWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only first letter of CLAWS PoS tags\n",
    "\n",
    "texts_df.toks_POS_CLAWS = texts_df.toks_POS_CLAWS.apply(lambda row: [(x[0],x[1][0].lower()) for x in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove puncuation from CLAWS texts\n",
    "\n",
    "COCA_POS = sorted(list(set([x[1] for x in coca_freq_dict.keys()])))\n",
    "texts_df.toks_POS_CLAWS = texts_df.toks_POS_CLAWS.apply(lambda row: [x for x in row if x[1] in COCA_POS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check lemmas not in COCA dict\n",
    "\n",
    "sorted(list(set([x for y in texts_df.toks_POS_CLAWS.apply(lambda row: [x for x in row if (x[0].lower(),x[1]) not in coca_word_lemma_dict]).to_list() for x in y])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1_orig</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1_norm</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B1_orig  I disagree that point about children brought u...   \n",
       "1  B1_norm  I disagree that point about children brought u...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, disagree, that, point, about, children, br...   \n",
       "1  [I, disagree, that, point, about, children, br...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "1  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (disagree, v), (that, d), (point, n),...   \n",
       "1  [(I, p), (disagree, v), (that, d), (point, n),...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, disagree, that, point, about, child, bring...   \n",
       "1  [I, disagree, that, point, about, child, bring...   \n",
       "\n",
       "                                        lemmas_CLAWS  \n",
       "0  [(I, p), (disagree, v), (that, d), (point, n),...  \n",
       "1  [(I, p), (disagree, v), (that, d), (point, n),...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create CLAWS lemma column\n",
    "\n",
    "# First lower case all toks (as in the word_lemma dict)\n",
    "texts_df['lemmas_CLAWS'] = texts_df.toks_POS_CLAWS.apply(lambda row: [(x[0].lower(),x[1]) for x in row])\n",
    "\n",
    "# Then map dict\n",
    "texts_df.lemmas_CLAWS = texts_df.lemmas_CLAWS.apply(\n",
    "    lambda row:[coca_word_lemma_dict[x] if x in coca_word_lemma_dict else x for x in row])\n",
    "\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length\n",
    "Length counted manually rather than using the len(toks) or other RE-based counting. This is to ensure accuracy that would match how words are counted on IELTS tests (also done manually by examiners). These counts often match what Microsoft Word would provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary\n",
    "\n",
    "text_len = {'B1_orig':172,'B1_norm':250}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1_orig</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1_norm</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B1_orig  I disagree that point about children brought u...   \n",
       "1  B1_norm  I disagree that point about children brought u...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, disagree, that, point, about, children, br...   \n",
       "1  [I, disagree, that, point, about, children, br...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "1  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (disagree, v), (that, d), (point, n),...   \n",
       "1  [(I, p), (disagree, v), (that, d), (point, n),...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, disagree, that, point, about, child, bring...   \n",
       "1  [I, disagree, that, point, about, child, bring...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len  \n",
       "0  [(I, p), (disagree, v), (that, d), (point, n),...       172  \n",
       "1  [(I, p), (disagree, v), (that, d), (point, n),...       250  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create length column\n",
    "\n",
    "texts_df['text_len'] = texts_df.text_id.map(text_len)\n",
    "texts_df['text_len'] = texts_df['text_len'].astype(int)\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic complexity\n",
    "\n",
    "Analysis using [TAASSC](https://www.linguisticanalysistools.org/taassc.html), calculating the measures from Lu's (2010) [Syntactic Complexity Analyzer](https://aihaiyang.com/software/). Based on previous research, two metrics most important for predicting proficiency are the focus: Number of complex nominals per clause (CN/C), and Mean length of clause (MLC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in TAASSC analysis file\n",
    "\n",
    "TAASSC = pd.read_csv(\"../docs/B1_TAASSC_sca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>nwords</th>\n",
       "      <th>MLS</th>\n",
       "      <th>MLT</th>\n",
       "      <th>MLC</th>\n",
       "      <th>C_S</th>\n",
       "      <th>VP_T</th>\n",
       "      <th>C_T</th>\n",
       "      <th>DC_C</th>\n",
       "      <th>DC_T</th>\n",
       "      <th>T_S</th>\n",
       "      <th>CT_T</th>\n",
       "      <th>CP_T</th>\n",
       "      <th>CP_C</th>\n",
       "      <th>CN_T</th>\n",
       "      <th>CN_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1_orig</td>\n",
       "      <td>172</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>15.636364</td>\n",
       "      <td>6.615385</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.727273</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>1.454545</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B1_norm</td>\n",
       "      <td>250</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>6.410256</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>2.437500</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>0.641026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  nwords        MLS        MLT       MLC  C_S      VP_T       C_T  \\\n",
       "1  B1_orig     172  17.200000  15.636364  6.615385  2.6  2.727273  2.363636   \n",
       "3  B1_norm     250  16.666667  15.625000  6.410256  2.6  2.875000  2.437500   \n",
       "\n",
       "       DC_C      DC_T       T_S      CT_T      CP_T      CP_C      CN_T  \\\n",
       "1  0.307692  0.727273  1.100000  0.545455  0.090909  0.038462  1.454545   \n",
       "3  0.358974  0.875000  1.066667  0.562500  0.187500  0.076923  1.562500   \n",
       "\n",
       "       CN_C  \n",
       "1  0.615385  \n",
       "3  0.641026  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename files to match texts_df\n",
    "\n",
    "file_names = {'B1_original_corrected.txt':'B1_orig','B1_normalized.txt':'B1_norm'}\n",
    "TAASSC.filename = TAASSC.filename.map(file_names)\n",
    "TAASSC = TAASSC.loc[~TAASSC.filename.isnull()]\n",
    "TAASSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1_orig</td>\n",
       "      <td>6.615385</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B1_norm</td>\n",
       "      <td>6.410256</td>\n",
       "      <td>0.641026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id       MLC       CNC\n",
       "1  B1_orig  6.615385  0.615385\n",
       "3  B1_norm  6.410256  0.641026"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only relevant syntactic complexity columns and rename them\n",
    "\n",
    "TAASSC = TAASSC[['filename','MLC','CN_C']]\n",
    "TAASSC = TAASSC.rename(columns={\"filename\": \"text_id\",'CN_C':'CNC'})\n",
    "TAASSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1_orig</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>172</td>\n",
       "      <td>6.615385</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1_norm</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>250</td>\n",
       "      <td>6.410256</td>\n",
       "      <td>0.641026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B1_orig  I disagree that point about children brought u...   \n",
       "1  B1_norm  I disagree that point about children brought u...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, disagree, that, point, about, children, br...   \n",
       "1  [I, disagree, that, point, about, children, br...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "1  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (disagree, v), (that, d), (point, n),...   \n",
       "1  [(I, p), (disagree, v), (that, d), (point, n),...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, disagree, that, point, about, child, bring...   \n",
       "1  [I, disagree, that, point, about, child, bring...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len       MLC  \\\n",
       "0  [(I, p), (disagree, v), (that, d), (point, n),...       172  6.615385   \n",
       "1  [(I, p), (disagree, v), (that, d), (point, n),...       250  6.410256   \n",
       "\n",
       "        CNC  \n",
       "0  0.615385  \n",
       "1  0.641026  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge TAASSC data with texts_df\n",
    "\n",
    "texts_df = pd.merge(texts_df, TAASSC, on='text_id')\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical diversity\n",
    "\n",
    "vocD (with lemmas) using functions from [PELITK](https://github.com/ELI-Data-Mining-Group/pelitk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation before calculating\n",
    "\n",
    "punctuation = ['.','!','?',';',':','#','\"',\"'\",'``','`',',','--','-','...',')','(',\"''\"]\n",
    "\n",
    "texts_df['vocD'] = texts_df.toks.apply(lambda row: [x for x in row if x not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "      <th>vocD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1_orig</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>172</td>\n",
       "      <td>6.615385</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>47.869657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1_norm</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>250</td>\n",
       "      <td>6.410256</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>48.723059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B1_orig  I disagree that point about children brought u...   \n",
       "1  B1_norm  I disagree that point about children brought u...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, disagree, that, point, about, children, br...   \n",
       "1  [I, disagree, that, point, about, children, br...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "1  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (disagree, v), (that, d), (point, n),...   \n",
       "1  [(I, p), (disagree, v), (that, d), (point, n),...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, disagree, that, point, about, child, bring...   \n",
       "1  [I, disagree, that, point, about, child, bring...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len       MLC  \\\n",
       "0  [(I, p), (disagree, v), (that, d), (point, n),...       172  6.615385   \n",
       "1  [(I, p), (disagree, v), (that, d), (point, n),...       250  6.410256   \n",
       "\n",
       "        CNC       vocD  \n",
       "0  0.615385  47.869657  \n",
       "1  0.641026  48.723059  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create vocD column\n",
    "\n",
    "texts_df['vocD'] = texts_df.lemmas_NLTK.apply(lex.vocd)\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical sophistication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Guiraud (AG)\n",
    "AG based on lemmas using a frequency list (PSL3) compiled from the PELIC learner corpus (see dissertation section 2.2.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['yesterday', 'yet', 'yogurt', 'you', 'young', 'your', 'yours', 'yourself', 'youth', 'zoo']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in PSL3 list for manual checking of items in texts that are off list\n",
    "\n",
    "f = open(\"../docs/psl3.txt\", \"r\")\n",
    "PSL3 = f.read()\n",
    "PSL3 = sorted(PSL3.split('\\n'))\n",
    "len(PSL3)\n",
    "PSL3[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "      <th>vocD</th>\n",
       "      <th>AG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1_orig</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>172</td>\n",
       "      <td>6.615385</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>47.869657</td>\n",
       "      <td>0.381246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1_norm</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>250</td>\n",
       "      <td>6.410256</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>48.723059</td>\n",
       "      <td>0.379473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B1_orig  I disagree that point about children brought u...   \n",
       "1  B1_norm  I disagree that point about children brought u...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, disagree, that, point, about, children, br...   \n",
       "1  [I, disagree, that, point, about, children, br...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "1  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (disagree, v), (that, d), (point, n),...   \n",
       "1  [(I, p), (disagree, v), (that, d), (point, n),...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, disagree, that, point, about, child, bring...   \n",
       "1  [I, disagree, that, point, about, child, bring...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len       MLC  \\\n",
       "0  [(I, p), (disagree, v), (that, d), (point, n),...       172  6.615385   \n",
       "1  [(I, p), (disagree, v), (that, d), (point, n),...       250  6.410256   \n",
       "\n",
       "        CNC       vocD        AG  \n",
       "0  0.615385  47.869657  0.381246  \n",
       "1  0.641026  48.723059  0.379473  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create AG column (punctuation removed)\n",
    "\n",
    "texts_df['AG'] = texts_df.lemmas_NLTK.apply(lambda row: [x for x in row if x not in punctuation]).apply(\n",
    "    lex.adv_guiraud,freq_list = 'PSL3')\n",
    "\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual diversity\n",
    "\n",
    "Analysis using [TAALES](https://www.linguisticanalysistools.org/taales.html). Based on previous research, one metric is the focus: contextual diversity as in Monteiro et al. (2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in TAALES analysis\n",
    "\n",
    "TAALES = pd.read_csv(\"../docs/B1_TAALES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename files to match texts_df\n",
    "\n",
    "TAALES.Filename = TAALES.Filename.map(file_names)\n",
    "TAALES = TAALES.loc[~TAALES.Filename.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>unigram_range</th>\n",
       "      <th>bigram_range</th>\n",
       "      <th>trigram_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1_norm</td>\n",
       "      <td>0.641003</td>\n",
       "      <td>0.094547</td>\n",
       "      <td>0.027453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B1_orig</td>\n",
       "      <td>0.631630</td>\n",
       "      <td>0.087890</td>\n",
       "      <td>0.027092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id  unigram_range  bigram_range  trigram_range\n",
       "0  B1_norm       0.641003      0.094547       0.027453\n",
       "4  B1_orig       0.631630      0.087890       0.027092"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only relevant contextual diversity columns and rename them\n",
    "\n",
    "TAALES = TAALES[['Filename','COCA_Academic_Range_AW','COCA_Academic_Bigram_Range','COCA_Academic_Trigram_Range']]\n",
    "TAALES = TAALES.rename(columns={\"Filename\": \"text_id\",'COCA_Academic_Range_AW':'unigram_range',\n",
    "                                'COCA_Academic_Bigram_Range':'bigram_range',\n",
    "                                'COCA_Academic_Trigram_Range':'trigram_range'})\n",
    "TAALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "      <th>vocD</th>\n",
       "      <th>AG</th>\n",
       "      <th>unigram_range</th>\n",
       "      <th>bigram_range</th>\n",
       "      <th>trigram_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1_orig</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>172</td>\n",
       "      <td>6.615385</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>47.869657</td>\n",
       "      <td>0.381246</td>\n",
       "      <td>0.631630</td>\n",
       "      <td>0.087890</td>\n",
       "      <td>0.027092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1_norm</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>250</td>\n",
       "      <td>6.410256</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>48.723059</td>\n",
       "      <td>0.379473</td>\n",
       "      <td>0.641003</td>\n",
       "      <td>0.094547</td>\n",
       "      <td>0.027453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B1_orig  I disagree that point about children brought u...   \n",
       "1  B1_norm  I disagree that point about children brought u...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, disagree, that, point, about, children, br...   \n",
       "1  [I, disagree, that, point, about, children, br...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "1  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (disagree, v), (that, d), (point, n),...   \n",
       "1  [(I, p), (disagree, v), (that, d), (point, n),...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, disagree, that, point, about, child, bring...   \n",
       "1  [I, disagree, that, point, about, child, bring...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len       MLC  \\\n",
       "0  [(I, p), (disagree, v), (that, d), (point, n),...       172  6.615385   \n",
       "1  [(I, p), (disagree, v), (that, d), (point, n),...       250  6.410256   \n",
       "\n",
       "        CNC       vocD        AG  unigram_range  bigram_range  trigram_range  \n",
       "0  0.615385  47.869657  0.381246       0.631630      0.087890       0.027092  \n",
       "1  0.641026  48.723059  0.379473       0.641003      0.094547       0.027453  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge TAALES data with texts_df\n",
    "\n",
    "texts_df = pd.merge(texts_df, TAALES, on='text_id')\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocation measures\n",
    "3 measures which make up 'CollGram' profile from Granger & Bestgen / Bestgen & Granger (2014):\n",
    "- mean MI\n",
    "- mean t-score\n",
    "- proportion or bigrams absent from reference corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract potential collocations in span 4\n",
    "\n",
    "def find_cols(lemma_list):\n",
    "    col_list = list(zip(lemma_list,lemma_list[1:]))+list(zip(lemma_list,lemma_list[2:]))\\\n",
    "    +list(zip(lemma_list,lemma_list[3:]))+list(zip(lemma_list,lemma_list[4:]))\n",
    "    return col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create possible collocations column\n",
    "\n",
    "texts_df['possible_cols'] = texts_df.lemmas_CLAWS.apply(find_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower-case (doesn't matter that 'I' gets lowered as not in collocate dict)\n",
    "\n",
    "texts_df['possible_cols'] = texts_df.possible_cols.apply(\n",
    "    lambda row: [((x[0][0].lower(),x[0][1]),(x[1][0].lower(),x[1][1])) for x in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('a', 'a'), ('about', 'i')), (('a', 'a'), ('and', 'c')), (('a', 'a'), ('child', 'n')), (('a', 'a'), ('culture', 'n')), (('a', 'a'), ('for', 'i'))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(('work', 'v'), ('work', 'v')), (('young', 'j'), ('do', 'v')), (('young', 'j'), ('for', 'i')), (('young', 'j'), ('they', 'p')), (('young', 'j'), ('work', 'n'))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "930"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of all possible collocations\n",
    "\n",
    "possible_cols = sorted(list(set([x for y in texts_df.possible_cols.to_list() for x in y])))\n",
    "possible_cols[:5]\n",
    "possible_cols[-5:]\n",
    "len(possible_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean MI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MI is not calculated for any bigrams with freq less than 5 or MI less than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column with MI for each possible collocation in MI dict\n",
    "\n",
    "texts_df['col_MI'] = texts_df.possible_cols.apply(lambda row: [(x,MI_dict[x]) for x in row if x in MI_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mean MI for each text based on tokens and types\n",
    "\n",
    "texts_df['mean_MI'] = texts_df.col_MI.apply(lambda row: np.mean([x[1] for x in row]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion of absent/low MI word combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column of two-word combinations not in collocation dict\n",
    "\n",
    "texts_df['absent'] = texts_df.possible_cols.apply(lambda row: [x for x in row if x not in col_freq_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find proportion of absent two-word combinations compared to total two-word combinations in the text\n",
    "\n",
    "texts_df['absent_prop'] = texts_df.absent.apply(lambda row: len(row)) / texts_df.possible_cols.apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find proportion of absent two-word combination types compared to total two-word combination types in the text\n",
    "\n",
    "texts_df['absent_prop_types'] = texts_df.absent.apply(lambda row: len(set(row))) / texts_df.possible_cols.apply(lambda row: len(set(row)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean t-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column with t-score for each bigram\n",
    "\n",
    "texts_df['col_tscore'] = texts_df.possible_cols.apply(lambda row: [(x,tscore_dict[x]) for x in row if x in tscore_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mean t-score for each text based on tokens and types\n",
    "\n",
    "texts_df['mean_tscore'] = texts_df.col_tscore.apply(lambda row: np.mean([x[1] for x in row]))\n",
    "texts_df['mean_tscore_types'] = texts_df.col_tscore.apply(lambda row: np.mean([x[1] for x in set(row)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "      <th>vocD</th>\n",
       "      <th>AG</th>\n",
       "      <th>unigram_range</th>\n",
       "      <th>bigram_range</th>\n",
       "      <th>trigram_range</th>\n",
       "      <th>possible_cols</th>\n",
       "      <th>col_MI</th>\n",
       "      <th>mean_MI</th>\n",
       "      <th>absent</th>\n",
       "      <th>absent_prop</th>\n",
       "      <th>absent_prop_types</th>\n",
       "      <th>col_tscore</th>\n",
       "      <th>mean_tscore</th>\n",
       "      <th>mean_tscore_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1_orig</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>172</td>\n",
       "      <td>6.615385</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>47.869657</td>\n",
       "      <td>0.381246</td>\n",
       "      <td>0.631630</td>\n",
       "      <td>0.087890</td>\n",
       "      <td>0.027092</td>\n",
       "      <td>[((i, p), (disagree, v)), ((disagree, v), (tha...</td>\n",
       "      <td>[((('our', 'a'), ('country', 'n')), 2.01), (((...</td>\n",
       "      <td>2.429286</td>\n",
       "      <td>[((i, p), (disagree, v)), ((disagree, v), (tha...</td>\n",
       "      <td>0.979228</td>\n",
       "      <td>0.980551</td>\n",
       "      <td>[((('our', 'a'), ('country', 'n')), 157.939), ...</td>\n",
       "      <td>115.839286</td>\n",
       "      <td>118.466583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1_norm</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>250</td>\n",
       "      <td>6.410256</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>48.723059</td>\n",
       "      <td>0.379473</td>\n",
       "      <td>0.641003</td>\n",
       "      <td>0.094547</td>\n",
       "      <td>0.027453</td>\n",
       "      <td>[((i, p), (disagree, v)), ((disagree, v), (tha...</td>\n",
       "      <td>[((('our', 'a'), ('country', 'n')), 2.01), (((...</td>\n",
       "      <td>2.522000</td>\n",
       "      <td>[((i, p), (disagree, v)), ((disagree, v), (tha...</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.986175</td>\n",
       "      <td>[((('our', 'a'), ('country', 'n')), 157.939), ...</td>\n",
       "      <td>111.671867</td>\n",
       "      <td>116.725000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B1_orig  I disagree that point about children brought u...   \n",
       "1  B1_norm  I disagree that point about children brought u...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, disagree, that, point, about, children, br...   \n",
       "1  [I, disagree, that, point, about, children, br...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "1  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (disagree, v), (that, d), (point, n),...   \n",
       "1  [(I, p), (disagree, v), (that, d), (point, n),...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, disagree, that, point, about, child, bring...   \n",
       "1  [I, disagree, that, point, about, child, bring...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len       MLC  \\\n",
       "0  [(I, p), (disagree, v), (that, d), (point, n),...       172  6.615385   \n",
       "1  [(I, p), (disagree, v), (that, d), (point, n),...       250  6.410256   \n",
       "\n",
       "        CNC       vocD        AG  unigram_range  bigram_range  trigram_range  \\\n",
       "0  0.615385  47.869657  0.381246       0.631630      0.087890       0.027092   \n",
       "1  0.641026  48.723059  0.379473       0.641003      0.094547       0.027453   \n",
       "\n",
       "                                       possible_cols  \\\n",
       "0  [((i, p), (disagree, v)), ((disagree, v), (tha...   \n",
       "1  [((i, p), (disagree, v)), ((disagree, v), (tha...   \n",
       "\n",
       "                                              col_MI   mean_MI  \\\n",
       "0  [((('our', 'a'), ('country', 'n')), 2.01), (((...  2.429286   \n",
       "1  [((('our', 'a'), ('country', 'n')), 2.01), (((...  2.522000   \n",
       "\n",
       "                                              absent  absent_prop  \\\n",
       "0  [((i, p), (disagree, v)), ((disagree, v), (tha...     0.979228   \n",
       "1  [((i, p), (disagree, v)), ((disagree, v), (tha...     0.984848   \n",
       "\n",
       "   absent_prop_types                                         col_tscore  \\\n",
       "0           0.980551  [((('our', 'a'), ('country', 'n')), 157.939), ...   \n",
       "1           0.986175  [((('our', 'a'), ('country', 'n')), 157.939), ...   \n",
       "\n",
       "   mean_tscore  mean_tscore_types  \n",
       "0   115.839286         118.466583  \n",
       "1   111.671867         116.725000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "Grammatical accuracy and collocational accuracy. Errors manually annotated and counted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grammatical accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create lists of manually identified errors\n",
    "\n",
    "B1_orig_grammar = ['they want they','had everything give','can do prepare','a money','they doing','could their money','(could) entrance to','their parents which persons','a pocket money','had a work']\n",
    "B1_norm_grammar = ['they want they','had everything give','can do prepare','a money','they doing','could their money','(could) entrance to','their parents which persons','a pocket money','had a work','could buying','they working','start a work','when they 15','and is good']\n",
    "\n",
    "len(B1_orig_grammar)\n",
    "len(B1_norm_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grammatical accuracy column\n",
    "\n",
    "grammar_dict = {'B1_orig':len(B1_orig_grammar),'B1_norm':len(B1_norm_grammar)}\n",
    "\n",
    "texts_df['grammar_errors'] = texts_df.text_id.map(grammar_dict)\n",
    "texts_df['grammar_errors_per_100'] = (texts_df.grammar_errors/texts_df.text_len)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add punctuation column (manually counted)\n",
    "\n",
    "punc_dict = {'B1_orig':13,'B1_norm':19}\n",
    "\n",
    "texts_df['punc_errors'] = texts_df.text_id.map(punc_dict)\n",
    "texts_df['punc_errors_per_100'] = (texts_df.punc_errors/texts_df.text_len)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocational accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Record of collocation errors. MI calculations not comparable with two and three word collocations.\n",
    "\n",
    "B1_orig_errors = ['disagree that point','show that situation','country parents','is not effect to','from twenty ages','social experience','age is late','work by (children ages)','culture about','could their money','country children','accept the money by','study at money','had a work']\n",
    "B1_norm_errors = ['disagree that point','show that situation','country parents','is not effect to','from twenty ages','social experience','age is late','work by (children ages)','culture about','could their money','country children','accept the money by','study at money','positive school','prepared their life','work my country','very disagree','prepare with many problems','for future time','had a work']\n",
    "\n",
    "len(B1_orig_errors)\n",
    "len(B1_norm_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accurate collocations (manually annotated)\n",
    "\n",
    "B1_orig_cols = ['good effect','on the other hand','in my case','start work','hear about','do work for','entrance to the bank','perfectly prepare']\n",
    "B1_norm_cols = ['good effect','on the other hand','in my case','start work','hear about','do work for','entrance to the bank','perfectly prepare','good parents','have money','work as a journalist','very young']\n",
    "\n",
    "len(B1_orig_cols)\n",
    "len(B1_norm_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'bad' cols column for future use\n",
    "\n",
    "texts_df['bad_cols'] = (B1_orig_errors,B1_norm_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create error and accurate cols columns\n",
    "\n",
    "errors_dict = {'B1_orig':len(B1_orig_errors),'B1_norm':len(B1_norm_errors)}\n",
    "correct_dict = {'B1_orig':len(B1_orig_cols),'B1_norm':len(B1_norm_cols)}\n",
    "\n",
    "texts_df['col_errors'] = texts_df.text_id.map(errors_dict)\n",
    "texts_df['correct_cols'] = texts_df.text_id.map(correct_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create errors and correct cols per 100 words columns\n",
    "\n",
    "texts_df['col_errors_per_100'] = (texts_df.col_errors/texts_df.text_len)*100\n",
    "texts_df['correct_cols_per_100'] = (texts_df.correct_cols/texts_df.text_len)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocation frequency bands\n",
    "Percentage of collocations containing low/mid/high freq items.  \n",
    "- High = K1-2\n",
    "- Mid = K3-9\n",
    "- Low = K10+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize collocations\n",
    "\n",
    "B1_orig_cols_toks = [x.split() for x in B1_orig_cols]\n",
    "B1_norm_cols_toks = [x.split() for x in B1_norm_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['good', 'effect'], ['on', 'the', 'other', 'hand'], ['in', 'my', 'case'], ['start', 'work'], ['hear', 'about'], ['do', 'work', 'for'], ['entrance', 'to', 'the', 'bank'], ['perfectly', 'prepare']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[['good', 'effect'], ['on', 'the', 'other', 'hand'], ['in', 'my', 'case'], ['start', 'work'], ['hear', 'about'], ['do', 'work', 'for'], ['entrance', 'to', 'the', 'bank'], ['perfectly', 'prepare'], ['good', 'parents'], ['have', 'money'], ['work', 'as', 'a', 'journalist'], ['very', 'young']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B1_orig_cols_toks\n",
    "B1_norm_cols_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collocations with PoS (manually lemmatized and tagged based on above)\n",
    "\n",
    "B1_orig_cols_toks_POS = [[('good','j'),('effect','n')],\n",
    "                         [('on','i'),('the','a'),('other','j'),('hand','n')],\n",
    "                         [('in','i'), ('my','a'), ('case','n')],\n",
    "                         [('start','v'),('work','n')],\n",
    "                         [('hear','v'),('about','i')],\n",
    "                         [('do','v'),('work','n'),('for','i')],\n",
    "                         [('entrance','n'), ('to', 'i'),('the','a'), ('bank','n')],\n",
    "                         [('perfectly','r'),('prepare','v')]]\n",
    "\n",
    "\n",
    "B1_norm_cols_toks_POS =  [[('good','j'),('effect','n')],\n",
    "                         [('on','i'),('the','a'),('other','j'),('hand','n')],\n",
    "                         [('in','i'), ('my','a'), ('case','n')],\n",
    "                         [('start','v'),('work','n')],\n",
    "                         [('hear','v'),('about','i')],\n",
    "                         [('do','v'),('work','n'),('for','i')],\n",
    "                         [('entrance','n'), ('to', 'i'),('the','a'), ('bank','n')],\n",
    "                         [('perfectly','r'),('prepare','v')],\n",
    "                         [('good','j'),('parent','n')],\n",
    "                         [('have','v'),('money','n')],\n",
    "                         [('work','v'),('as','i'),('a','a'),('journalist','n')],\n",
    "                         [('very','r'),('young','j')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create collocation dict\n",
    "\n",
    "col_dict = {'B1_orig':B1_orig_cols_toks_POS,'B1_norm':B1_norm_cols_toks_POS}\n",
    "\n",
    "# Create column with collocations\n",
    "\n",
    "texts_df['cols'] = texts_df.text_id.map(col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column of the freq bands of the highest kband item in each collocation\n",
    "\n",
    "texts_df['col_kband'] = texts_df.cols.apply(\n",
    "    lambda row:[sorted([kband_dict[y] for y in x],reverse=True)[0] for x in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create (kband, cols) tuples\n",
    "\n",
    "texts_df['kband_cols'] = list(zip(texts_df.col_kband,texts_df.cols))\n",
    "texts_df['kband_cols'] = texts_df['kband_cols'].apply(lambda row: list(zip(row[0],row[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Kbands\n",
    "\n",
    "high_freq_K = list(range(1,3))\n",
    "mid_freq_K = list(range(3,10))\n",
    "low_freq_K = list(range(10,101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns of percentages of cols that contain low, med, high kband items (highest only)\n",
    "\n",
    "texts_df['K10to16_cols'] = texts_df.col_kband.apply(lambda row: len([x for x in row if x in(low_freq_K)]))\n",
    "texts_df['K3to9_cols'] = texts_df.col_kband.apply(lambda row: len([x for x in row if x in(mid_freq_K)]))\n",
    "texts_df['K1to2_cols'] = texts_df.col_kband.apply(lambda row: len([x for x in row if x in(high_freq_K)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add percent columns\n",
    "\n",
    "texts_df['K10to16_p'] = texts_df['K10to16_cols']/(texts_df['K10to16_cols']+texts_df['K3to9_cols']+texts_df['K1to2_cols'])\n",
    "texts_df['K3to9_p'] = texts_df['K3to9_cols']/(texts_df['K10to16_cols']+texts_df['K3to9_cols']+texts_df['K1to2_cols'])\n",
    "texts_df['K1to2_p'] = texts_df['K1to2_cols']/(texts_df['K10to16_cols']+texts_df['K3to9_cols']+texts_df['K1to2_cols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate columns with low/mid/high cols for ease of viewing\n",
    "\n",
    "texts_df['K1to2_cols_K'] = texts_df.kband_cols.apply(lambda row: [x for x in row if x[0] <= 2])\n",
    "texts_df['K3to9_cols_K'] = texts_df.kband_cols.apply(lambda row: [x for x in row if 10 > x[0] > 2])\n",
    "texts_df['K10to16_cols_K'] = texts_df.kband_cols.apply(lambda row: [x for x in row if x[0] > 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "      <th>vocD</th>\n",
       "      <th>AG</th>\n",
       "      <th>unigram_range</th>\n",
       "      <th>bigram_range</th>\n",
       "      <th>trigram_range</th>\n",
       "      <th>possible_cols</th>\n",
       "      <th>col_MI</th>\n",
       "      <th>mean_MI</th>\n",
       "      <th>absent</th>\n",
       "      <th>absent_prop</th>\n",
       "      <th>absent_prop_types</th>\n",
       "      <th>col_tscore</th>\n",
       "      <th>mean_tscore</th>\n",
       "      <th>mean_tscore_types</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>grammar_errors_per_100</th>\n",
       "      <th>punc_errors</th>\n",
       "      <th>punc_errors_per_100</th>\n",
       "      <th>bad_cols</th>\n",
       "      <th>col_errors</th>\n",
       "      <th>correct_cols</th>\n",
       "      <th>col_errors_per_100</th>\n",
       "      <th>correct_cols_per_100</th>\n",
       "      <th>cols</th>\n",
       "      <th>col_kband</th>\n",
       "      <th>kband_cols</th>\n",
       "      <th>K10to16_cols</th>\n",
       "      <th>K3to9_cols</th>\n",
       "      <th>K1to2_cols</th>\n",
       "      <th>K10to16_p</th>\n",
       "      <th>K3to9_p</th>\n",
       "      <th>K1to2_p</th>\n",
       "      <th>K1to2_cols_K</th>\n",
       "      <th>K3to9_cols_K</th>\n",
       "      <th>K10to16_cols_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1_orig</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>172</td>\n",
       "      <td>6.615</td>\n",
       "      <td>0.615</td>\n",
       "      <td>47.870</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.027</td>\n",
       "      <td>[((i, p), (disagree, v)), ((disagree, v), (tha...</td>\n",
       "      <td>[((('our', 'a'), ('country', 'n')), 2.01), (((...</td>\n",
       "      <td>2.429</td>\n",
       "      <td>[((i, p), (disagree, v)), ((disagree, v), (tha...</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.981</td>\n",
       "      <td>[((('our', 'a'), ('country', 'n')), 157.939), ...</td>\n",
       "      <td>115.839</td>\n",
       "      <td>118.467</td>\n",
       "      <td>10</td>\n",
       "      <td>5.814</td>\n",
       "      <td>13</td>\n",
       "      <td>7.558</td>\n",
       "      <td>[disagree that point, show that situation, cou...</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>8.14</td>\n",
       "      <td>4.651</td>\n",
       "      <td>[[(good, j), (effect, n)], [(on, i), (the, a),...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 4, 3]</td>\n",
       "      <td>[(1, [('good', 'j'), ('effect', 'n')]), (1, [(...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>[(1, [('good', 'j'), ('effect', 'n')]), (1, [(...</td>\n",
       "      <td>[(4, [('entrance', 'n'), ('to', 'i'), ('the', ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1_norm</td>\n",
       "      <td>I disagree that point about children brought u...</td>\n",
       "      <td>[I, disagree, that, point, about, children, br...</td>\n",
       "      <td>[(I, PRP), (disagree, VBP), (that, IN), (point...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>[I, disagree, that, point, about, child, bring...</td>\n",
       "      <td>[(I, p), (disagree, v), (that, d), (point, n),...</td>\n",
       "      <td>250</td>\n",
       "      <td>6.410</td>\n",
       "      <td>0.641</td>\n",
       "      <td>48.723</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.027</td>\n",
       "      <td>[((i, p), (disagree, v)), ((disagree, v), (tha...</td>\n",
       "      <td>[((('our', 'a'), ('country', 'n')), 2.01), (((...</td>\n",
       "      <td>2.522</td>\n",
       "      <td>[((i, p), (disagree, v)), ((disagree, v), (tha...</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.986</td>\n",
       "      <td>[((('our', 'a'), ('country', 'n')), 157.939), ...</td>\n",
       "      <td>111.672</td>\n",
       "      <td>116.725</td>\n",
       "      <td>15</td>\n",
       "      <td>6.000</td>\n",
       "      <td>19</td>\n",
       "      <td>7.600</td>\n",
       "      <td>[disagree that point, show that situation, cou...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.800</td>\n",
       "      <td>[[(good, j), (effect, n)], [(on, i), (the, a),...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 4, 3, 1, 1, 3, 1]</td>\n",
       "      <td>[(1, [('good', 'j'), ('effect', 'n')]), (1, [(...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>[(1, [('good', 'j'), ('effect', 'n')]), (1, [(...</td>\n",
       "      <td>[(4, [('entrance', 'n'), ('to', 'i'), ('the', ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  B1_orig  I disagree that point about children brought u...   \n",
       "1  B1_norm  I disagree that point about children brought u...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, disagree, that, point, about, children, br...   \n",
       "1  [I, disagree, that, point, about, children, br...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "1  [(I, PRP), (disagree, VBP), (that, IN), (point...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (disagree, v), (that, d), (point, n),...   \n",
       "1  [(I, p), (disagree, v), (that, d), (point, n),...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, disagree, that, point, about, child, bring...   \n",
       "1  [I, disagree, that, point, about, child, bring...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len    MLC    CNC  \\\n",
       "0  [(I, p), (disagree, v), (that, d), (point, n),...       172  6.615  0.615   \n",
       "1  [(I, p), (disagree, v), (that, d), (point, n),...       250  6.410  0.641   \n",
       "\n",
       "     vocD     AG  unigram_range  bigram_range  trigram_range  \\\n",
       "0  47.870  0.381          0.632         0.088          0.027   \n",
       "1  48.723  0.379          0.641         0.095          0.027   \n",
       "\n",
       "                                       possible_cols  \\\n",
       "0  [((i, p), (disagree, v)), ((disagree, v), (tha...   \n",
       "1  [((i, p), (disagree, v)), ((disagree, v), (tha...   \n",
       "\n",
       "                                              col_MI  mean_MI  \\\n",
       "0  [((('our', 'a'), ('country', 'n')), 2.01), (((...    2.429   \n",
       "1  [((('our', 'a'), ('country', 'n')), 2.01), (((...    2.522   \n",
       "\n",
       "                                              absent  absent_prop  \\\n",
       "0  [((i, p), (disagree, v)), ((disagree, v), (tha...        0.979   \n",
       "1  [((i, p), (disagree, v)), ((disagree, v), (tha...        0.985   \n",
       "\n",
       "   absent_prop_types                                         col_tscore  \\\n",
       "0              0.981  [((('our', 'a'), ('country', 'n')), 157.939), ...   \n",
       "1              0.986  [((('our', 'a'), ('country', 'n')), 157.939), ...   \n",
       "\n",
       "   mean_tscore  mean_tscore_types  grammar_errors  grammar_errors_per_100  \\\n",
       "0      115.839            118.467              10                   5.814   \n",
       "1      111.672            116.725              15                   6.000   \n",
       "\n",
       "   punc_errors  punc_errors_per_100  \\\n",
       "0           13                7.558   \n",
       "1           19                7.600   \n",
       "\n",
       "                                            bad_cols  col_errors  \\\n",
       "0  [disagree that point, show that situation, cou...          14   \n",
       "1  [disagree that point, show that situation, cou...          20   \n",
       "\n",
       "   correct_cols  col_errors_per_100  correct_cols_per_100  \\\n",
       "0             8                8.14                 4.651   \n",
       "1            12                8.00                 4.800   \n",
       "\n",
       "                                                cols  \\\n",
       "0  [[(good, j), (effect, n)], [(on, i), (the, a),...   \n",
       "1  [[(good, j), (effect, n)], [(on, i), (the, a),...   \n",
       "\n",
       "                              col_kband  \\\n",
       "0              [1, 1, 1, 1, 1, 1, 4, 3]   \n",
       "1  [1, 1, 1, 1, 1, 1, 4, 3, 1, 1, 3, 1]   \n",
       "\n",
       "                                          kband_cols  K10to16_cols  \\\n",
       "0  [(1, [('good', 'j'), ('effect', 'n')]), (1, [(...             0   \n",
       "1  [(1, [('good', 'j'), ('effect', 'n')]), (1, [(...             0   \n",
       "\n",
       "   K3to9_cols  K1to2_cols  K10to16_p  K3to9_p  K1to2_p  \\\n",
       "0           2           6        0.0     0.25     0.75   \n",
       "1           3           9        0.0     0.25     0.75   \n",
       "\n",
       "                                        K1to2_cols_K  \\\n",
       "0  [(1, [('good', 'j'), ('effect', 'n')]), (1, [(...   \n",
       "1  [(1, [('good', 'j'), ('effect', 'n')]), (1, [(...   \n",
       "\n",
       "                                        K3to9_cols_K K10to16_cols_K  \n",
       "0  [(4, [('entrance', 'n'), ('to', 'i'), ('the', ...             []  \n",
       "1  [(4, [('entrance', 'n'), ('to', 'i'), ('the', ...             []  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round all stats to 3 digits for ease of use\n",
    "\n",
    "texts_df = round(texts_df,3)\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing length\n",
    "\n",
    "Results of comparison between original and normalized versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function for finding range of + or - 5%\n",
    "\n",
    "def find_range(stat):\n",
    "    low = str(round(stat*.95,2))\n",
    "    high = str(round(stat*1.05,2))\n",
    "    stat_range = low + ' - ' + high\n",
    "    return stat_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47.87, 48.723]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'45.48 - 50.26'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocD: mod within 5% of orig (remember that changes slightly every time calculated as based on samples)\n",
    "\n",
    "B1_vocd = texts_df['vocD'].to_list()\n",
    "B1_vocd \n",
    "\n",
    "find_range(B1_vocd[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.381, 0.379]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.36 - 0.4'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AG (PSL): mod within 5% of orig\n",
    "\n",
    "B1_AG = texts_df['AG'].to_list()\n",
    "B1_AG\n",
    "\n",
    "find_range(B1_AG[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.429, 2.522]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'2.31 - 2.55'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean MI (words): mod within 5% of orig\n",
    "\n",
    "B1_mean_MI = texts_df['mean_MI'].to_list()\n",
    "B1_mean_MI\n",
    "\n",
    "find_range(B1_mean_MI[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[115.839, 111.672]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'110.05 - 121.63'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean t-score (words): mod within 5% of orig\n",
    "\n",
    "B1_mean_t_score = texts_df['mean_tscore'].to_list()\n",
    "B1_mean_t_score\n",
    "\n",
    "find_range(B1_mean_t_score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.979, 0.985]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.93 - 1.03'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean proportion of bigrams (words): mod within 5% of orig or closest possible (see B2)\n",
    "\n",
    "B1_absent_prop = texts_df['absent_prop'].to_list()\n",
    "B1_absent_prop\n",
    "\n",
    "find_range(B1_absent_prop[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.814, 6.0]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'5.52 - 6.1'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grammar errors per 100: mod within 5% of orig\n",
    "\n",
    "B1_grammar_errors_per_100 = texts_df['grammar_errors_per_100'].to_list()\n",
    "B1_grammar_errors_per_100\n",
    "\n",
    "find_range(B1_grammar_errors_per_100[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.558, 7.6]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'7.18 - 7.94'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Punctuation errors per 100: mod within 5% of orig\n",
    "\n",
    "B1_punc_errors_per_100 = texts_df['punc_errors_per_100'].to_list()\n",
    "B1_punc_errors_per_100\n",
    "\n",
    "find_range(B1_punc_errors_per_100[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.14, 8.0]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'7.73 - 8.55'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collocation errors per 100: mod within 5% of orig\n",
    "\n",
    "B1_col_errors_per_100 = texts_df['col_errors_per_100'].to_list()\n",
    "B1_col_errors_per_100\n",
    "\n",
    "find_range(B1_col_errors_per_100[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.651, 4.8]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'4.42 - 4.88'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accurate colls per 100\n",
    "\n",
    "B1_correct_cols_per_100 = texts_df['correct_cols_per_100'].to_list()\n",
    "B1_correct_cols_per_100\n",
    "\n",
    "find_range(B1_correct_cols_per_100[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.0 - 0.0'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K10-16 cols percent\n",
    "\n",
    "B1_K10to16_p = texts_df['K10to16_p'].to_list()\n",
    "B1_K10to16_p\n",
    "\n",
    "find_range(B1_K10to16_p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.25, 0.25]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.24 - 0.26'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K3-9 cols percent\n",
    "\n",
    "B1_K3to9_p = texts_df['K3to9_p'].to_list()\n",
    "B1_K3to9_p\n",
    "\n",
    "find_range(B1_K3to9_p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.75, 0.75]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.71 - 0.79'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K1-2 cols percent\n",
    "\n",
    "B1_K1to2_p = texts_df['K1to2_p'].to_list()\n",
    "B1_K1to2_p\n",
    "\n",
    "find_range(B1_K1to2_p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.088, 0.095]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.08 - 0.09'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bigram range: mod within 5% of orig\n",
    "\n",
    "B1_bigram_range = texts_df['bigram_range'].to_list()\n",
    "B1_bigram_range\n",
    "\n",
    "find_range(B1_bigram_range[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.615, 0.641]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.58 - 0.65'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNC: mod within 5% of orig\n",
    "\n",
    "B1_CNC = texts_df['CNC'].to_list()\n",
    "B1_CNC\n",
    "\n",
    "find_range(B1_CNC[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.615, 6.41]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'6.28 - 6.95'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLC: mod within 5% of orig\n",
    "\n",
    "B1_MLC = texts_df['MLC'].to_list()\n",
    "B1_MLC\n",
    "\n",
    "find_range(B1_MLC[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison with relevant stats only\n",
    "\n",
    "texts_final = texts_df[['text_id','text','lemmas_NLTK','lemmas_CLAWS','text_len','MLC','CNC','grammar_errors_per_100',\n",
    "                        'punc_errors_per_100','vocD','AG','bigram_range','mean_MI','absent_prop',\n",
    "                        'mean_tscore','col_errors_per_100','correct_cols_per_100','K10to16_p','K3to9_p','K1to2_p',\n",
    "                        'kband_cols', 'K1to2_cols','K3to9_cols','K10to16_cols',\n",
    "                        'K1to2_cols_K','K3to9_cols_K','K10to16_cols_K','bad_cols']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../docs/B1_orig&norm.pkl']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pickle for later use\n",
    "\n",
    "joblib.dump(texts_final ,'../docs/B1_orig&norm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../docs/B1_cols.pkl']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pickle possible cols for collocation identification notebook\n",
    "\n",
    "B1_cols = texts_df[['text_id','lemmas_CLAWS','possible_cols']]\n",
    "\n",
    "joblib.dump(B1_cols ,'../docs/B1_cols.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Normalizing-B1-original-text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
