{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing C1 original text\n",
    "\n",
    "<br>\n",
    "\n",
    "**Language: Python**\n",
    "\n",
    "This notebook shows the process used for creating the length-normalized C1 text from the original public IELTS Task 2 C1 text. The original text is a public academic writing sample from the [IELTS website](https://www.ielts.org/en-us/about-the-test/sample-test-questions). The original text is 254 words and the desired length is 250 words (see chapters 5.1 and 5.2 of the dissertation).\n",
    "\n",
    "**Notebook contents:**\n",
    "- [Initial setup](#Initial-setup)\n",
    "- [Text processing](#Text-processing)\n",
    "- [Syntactic complexity](#Syntactic-complexity)\n",
    "- [Lexical diversity](#Lexical-diversity)\n",
    "- [Lexical sophistication](#Lexical-sophistication)\n",
    "- [Collocation measures](#Collocation-measures)\n",
    "- [Accuracy](#Accuracy)\n",
    "- [Normalizing length](#Normalizing-length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import csv\n",
    "from ast import literal_eval\n",
    "from nltk import pos_tag_sents\n",
    "from pelitk import lex\n",
    "import joblib\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "# Set preferred notebook format\n",
    "\n",
    "%pprint # Turn off pretty printing\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # Show all output, not just last item\n",
    "pd.set_option('display.max_columns', 999) # Allow viewing of all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** As described in the [README.md]('../README.md'), The frequency information from COCA referenced here is not freely available but can be purchased at https://corpus.byu.edu/coca. Without this data you will be able to see a few rows of these dataframes, but will not be able to run the code yourself. The t-scores and K-bands were also calculated using these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary dictionaries\n",
    "\n",
    "coca_freq_dict = joblib.load('../../COCA_data/COCA_2020_lemma_freq_dict.pkl')\n",
    "coca_word_lemma_dict = joblib.load('../../COCA_data/COCA_2020_word_lemma_dict.pkl')\n",
    "col_freq_dict = joblib.load('../../COCA_data/COCA_2020_collocate_freq_dict.pkl')\n",
    "MI_dict = joblib.load('../../COCA_data/COCA_2020_MI_dict.pkl')\n",
    "tscore_dict = joblib.load('../../COCA_data/COCA_2020_tscore_dict.pkl')\n",
    "kband_dict = joblib.load('../../COCA_data/COCA_2020_lemma_Kband_dict.pkl') # All items lower-case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in original text (transcribed and with corrected spelling)\n",
    "\n",
    "f = open(\"../docs/C1_original_corrected.txt\", \"r\")\n",
    "C1_orig = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In addition to correcting spelling, contractions were changed to full words, '&' to 'and', '20' to 'twenty', and 'Mr' to 'Mister'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in modified text\n",
    "\n",
    "f = open(\"../docs/C1_normalized.txt\", \"r\")\n",
    "C1_norm = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** These modified texts were modified based on the [`Normalizing length`](#Normalizing-length) goals described later, but are incorporated here to avoid having to go through the text processing procedure twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_orig</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_norm</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text\n",
       "0  C1_orig  I do agree to the statement that children brou...\n",
       "1  C1_norm  I do agree to the statement that children brou..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe\n",
    "\n",
    "texts_df = pd.DataFrame({'text_id':pd.Series(['C1_orig','C1_norm']),\n",
    "                         'text':pd.Series([C1_orig,C1_norm])})\n",
    "\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing\n",
    "\n",
    "The tokenizer, part-of-speech tagger, and lemmatizer tools are the same ones used in the creation of the [PELIC](https://github.com/ELI-Data-Mining-Group/PELIC-dataset) corpus. The tokenizer and lemmatizer are not open access but are based on the ones from [NLTK](https://www.nltk.org/), and using the public NLTK tools will yield similar results. For a more detailed description of the modified tools, please see [Naismith et al. (2022)](https://benjamins.com/catalog/ijlcr.21002.nai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Ben/Documents/ELI_Data_Mining/Data-Archive/elitools\n"
     ]
    }
   ],
   "source": [
    "# Change to working directory containing elitools\n",
    "\n",
    "%cd '../../ELI_Data_Mining/Data-Archive/elitools/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lemmatizer\n",
    "\n",
    "%run -i 'lemmatizer_class.py'\n",
    "lemmatizer = lemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer module\n",
    "\n",
    "%run -i 'tokenizer.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Ben/Documents/Collocational_proficiency_Naismith_2022/notebooks\n"
     ]
    }
   ],
   "source": [
    "# Return to previous working directory\n",
    "\n",
    "%cd '../../../Collocational_proficiency_Naismith_2022/notebooks'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_orig</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_norm</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  C1_orig  I do agree to the statement that children brou...   \n",
       "1  C1_norm  I do agree to the statement that children brou...   \n",
       "\n",
       "                                                toks  \n",
       "0  [I, do, agree, to, the, statement, that, child...  \n",
       "1  [I, do, agree, to, the, statement, that, child...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize text (nltk-based)\n",
    "\n",
    "texts_df['toks'] = texts_df.text.apply(tokenize)\n",
    "\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS tagging\n",
    "- NLTK (PELIC)\n",
    "- CLAWS7 (COCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK\n",
    "As there are only three texts (each with three versions), to avoid any errors, I have used the default NLTK tagger (Penn Treebank tagset), then manually checked and corrected the tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply nltk tagger to create series\n",
    "\n",
    "C1_NLTK = pd.Series(pos_tag_sents(texts_df['toks']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-d2277c1b7b90>:7: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  C1_NLTK_CHECKED = pd.read_csv(\"../docs/C1_NLTK_CHECKED.csv\", header=None, squeeze = True)\n"
     ]
    }
   ],
   "source": [
    "# Check tags\n",
    "\n",
    "# Write out tagged texts\n",
    "C1_NLTK.to_csv('../docs/C1_NLTK.csv', index=False, header=False) \n",
    "\n",
    "# Read in the checked tagged texts as a series\n",
    "C1_NLTK_CHECKED = pd.read_csv(\"../docs/C1_NLTK_CHECKED.csv\", header=None, squeeze = True) \n",
    "C1_NLTK_CHECKED = [literal_eval(x) for x in C1_NLTK_CHECKED]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_orig</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_norm</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  C1_orig  I do agree to the statement that children brou...   \n",
       "1  C1_norm  I do agree to the statement that children brou...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        tok_POS_NLTK  \n",
       "0  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...  \n",
       "1  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create column based on checked tagged texts\n",
    "\n",
    "texts_df['tok_POS_NLTK'] = C1_NLTK_CHECKED\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLAWS7\n",
    "\n",
    "By also tagging with CLAWS7, it is easier to match the POS to the COCA info, rather than the Penn tagset used by NLTK and then having to convert.\n",
    "\n",
    "Free CLAWS tagger: http://ucrel-api.lancaster.ac.uk/claws/free.html\n",
    "\n",
    "Again, these tagged texts should be manually checked prior to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in tagged CLAWS texts\n",
    "\n",
    "f = open(\"../docs/C1_original_CLAWS.txt\", \"r\")\n",
    "C1_orig_CLAWS = f.read()\n",
    "\n",
    "f = open(\"../docs/C1_normalized_CLAWS.txt\", \"r\")\n",
    "C1_norm_CLAWS = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove new line characters, split on whitespace, and remove identifier at end\n",
    "\n",
    "C1_orig_CLAWS = C1_orig_CLAWS.replace('\\n', '').split(' ')[:-2]\n",
    "C1_norm_CLAWS = C1_norm_CLAWS.replace('\\n', '').split(' ')[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change tags into tuples\n",
    "\n",
    "C1_orig_CLAWS = [tuple(x.split('_')) for x in C1_orig_CLAWS]\n",
    "C1_norm_CLAWS = [tuple(x.split('_')) for x in C1_norm_CLAWS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_orig</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, PPIS1), (do, VD0), (agree, VVI), (to, II)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_norm</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, PPIS1), (do, VD0), (agree, VVI), (to, II)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  C1_orig  I do agree to the statement that children brou...   \n",
       "1  C1_norm  I do agree to the statement that children brou...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "1  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \n",
       "0  [(I, PPIS1), (do, VD0), (agree, VVI), (to, II)...  \n",
       "1  [(I, PPIS1), (do, VD0), (agree, VVI), (to, II)...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df['toks_POS_CLAWS'] = pd.Series([C1_orig_CLAWS,C1_norm_CLAWS])\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_orig</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, PPIS1), (do, VD0), (agree, VVI), (to, II)...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_norm</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, PPIS1), (do, VD0), (agree, VVI), (to, II)...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  C1_orig  I do agree to the statement that children brou...   \n",
       "1  C1_norm  I do agree to the statement that children brou...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "1  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, PPIS1), (do, VD0), (agree, VVI), (to, II)...   \n",
       "1  [(I, PPIS1), (do, VD0), (agree, VVI), (to, II)...   \n",
       "\n",
       "                                         lemmas_NLTK  \n",
       "0  [I, do, agree, to, the, statement, that, child...  \n",
       "1  [I, do, agree, to, the, statement, that, child...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create lemmatized text column using our lemmatizer loaded earlier\n",
    "\n",
    "texts_df['lemmas_NLTK'] = texts_df['tok_POS_NLTK'].apply(lemmatizer.lemmatize_text)\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLAWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only first letter of CLAWS PoS tags\n",
    "\n",
    "texts_df.toks_POS_CLAWS = texts_df.toks_POS_CLAWS.apply(lambda row: [(x[0],x[1][0].lower()) for x in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove puncuation from CLAWS texts\n",
    "\n",
    "COCA_POS = sorted(list(set([x[1] for x in coca_freq_dict.keys()])))\n",
    "texts_df.toks_POS_CLAWS = texts_df.toks_POS_CLAWS.apply(lambda row: [x for x in row if x[1] in COCA_POS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'realities\", 'n'), ('Microsoft', 'n')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check lemmas not in COCA dict\n",
    "\n",
    "sorted(list(set([x for y in texts_df.toks_POS_CLAWS.apply(lambda row: [x for x in row if (x[0].lower(),x[1]) not in coca_word_lemma_dict]).to_list() for x in y])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_orig</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_norm</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  C1_orig  I do agree to the statement that children brou...   \n",
       "1  C1_norm  I do agree to the statement that children brou...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "1  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        lemmas_CLAWS  \n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...  \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create CLAWS lemma column\n",
    "\n",
    "# First lower case all toks (as in the word_lemma dict)\n",
    "texts_df['lemmas_CLAWS'] = texts_df.toks_POS_CLAWS.apply(lambda row: [(x[0].lower(),x[1]) for x in row])\n",
    "\n",
    "# Then map dict\n",
    "texts_df.lemmas_CLAWS = texts_df.lemmas_CLAWS.apply(\n",
    "    lambda row:[coca_word_lemma_dict[x] if x in coca_word_lemma_dict else x for x in row])\n",
    "\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length\n",
    "Length counted manually rather than using the len(toks) or other RE-based counting. This is to ensure accuracy that would match how words are counted on IELTS tests (also done manually by examiners). These counts often match what Microsoft Word would provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary\n",
    "\n",
    "text_len = {'C1_orig':254,'C1_norm':250}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_orig</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_norm</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  C1_orig  I do agree to the statement that children brou...   \n",
       "1  C1_norm  I do agree to the statement that children brou...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "1  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len  \n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...       254  \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...       250  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create length column\n",
    "\n",
    "texts_df['text_len'] = texts_df.text_id.map(text_len)\n",
    "texts_df['text_len'] = texts_df['text_len'].astype(int)\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic complexity\n",
    "\n",
    "Analysis using [TAASSC](https://www.linguisticanalysistools.org/taassc.html), calculating the measures from Lu's (2010) [Syntactic Complexity Analyzer](https://aihaiyang.com/software/). Based on previous research, two metrics most important for predicting proficiency are the focus: Number of complex nominals per clause (CN/C), and Mean length of clause (MLC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in TAASSC analysis file\n",
    "\n",
    "TAASSC = pd.read_csv(\"../docs/C1_TAASSC_sca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>nwords</th>\n",
       "      <th>MLS</th>\n",
       "      <th>MLT</th>\n",
       "      <th>MLC</th>\n",
       "      <th>C_S</th>\n",
       "      <th>VP_T</th>\n",
       "      <th>C_T</th>\n",
       "      <th>DC_C</th>\n",
       "      <th>DC_T</th>\n",
       "      <th>T_S</th>\n",
       "      <th>CT_T</th>\n",
       "      <th>CP_T</th>\n",
       "      <th>CP_C</th>\n",
       "      <th>CN_T</th>\n",
       "      <th>CN_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_orig</td>\n",
       "      <td>259</td>\n",
       "      <td>16.1875</td>\n",
       "      <td>15.235294</td>\n",
       "      <td>11.772727</td>\n",
       "      <td>1.375</td>\n",
       "      <td>1.823529</td>\n",
       "      <td>1.294118</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>1.0625</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>2.647059</td>\n",
       "      <td>2.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C1_norm</td>\n",
       "      <td>255</td>\n",
       "      <td>15.9375</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.590909</td>\n",
       "      <td>1.375</td>\n",
       "      <td>1.823529</td>\n",
       "      <td>1.294118</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>1.0625</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>2.647059</td>\n",
       "      <td>2.045455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  nwords      MLS        MLT        MLC    C_S      VP_T       C_T  \\\n",
       "0  C1_orig     259  16.1875  15.235294  11.772727  1.375  1.823529  1.294118   \n",
       "5  C1_norm     255  15.9375  15.000000  11.590909  1.375  1.823529  1.294118   \n",
       "\n",
       "       DC_C      DC_T     T_S      CT_T      CP_T      CP_C      CN_T  \\\n",
       "0  0.227273  0.294118  1.0625  0.294118  0.470588  0.363636  2.647059   \n",
       "5  0.227273  0.294118  1.0625  0.294118  0.411765  0.318182  2.647059   \n",
       "\n",
       "       CN_C  \n",
       "0  2.045455  \n",
       "5  2.045455  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename files to match texts_df\n",
    "\n",
    "file_names = {'C1_original_corrected.txt':'C1_orig','C1_normalized.txt':'C1_norm'}\n",
    "TAASSC.filename = TAASSC.filename.map(file_names)\n",
    "TAASSC = TAASSC.loc[~TAASSC.filename.isnull()]\n",
    "TAASSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_orig</td>\n",
       "      <td>11.772727</td>\n",
       "      <td>2.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C1_norm</td>\n",
       "      <td>11.590909</td>\n",
       "      <td>2.045455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id        MLC       CNC\n",
       "0  C1_orig  11.772727  2.045455\n",
       "5  C1_norm  11.590909  2.045455"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only relevant syntactic complexity columns and rename them\n",
    "\n",
    "TAASSC = TAASSC[['filename','MLC','CN_C']]\n",
    "TAASSC = TAASSC.rename(columns={\"filename\": \"text_id\",'CN_C':'CNC'})\n",
    "TAASSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_orig</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>254</td>\n",
       "      <td>11.772727</td>\n",
       "      <td>2.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_norm</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>250</td>\n",
       "      <td>11.590909</td>\n",
       "      <td>2.045455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  C1_orig  I do agree to the statement that children brou...   \n",
       "1  C1_norm  I do agree to the statement that children brou...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "1  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len        MLC  \\\n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...       254  11.772727   \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...       250  11.590909   \n",
       "\n",
       "        CNC  \n",
       "0  2.045455  \n",
       "1  2.045455  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge TAASSC data with texts_df\n",
    "\n",
    "texts_df = pd.merge(texts_df, TAASSC, on='text_id')\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical diversity\n",
    "\n",
    "vocD (with lemmas) using functions from [PELITK](https://github.com/ELI-Data-Mining-Group/pelitk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation before calculating\n",
    "\n",
    "punctuation = ['.','!','?',';',':','#','\"',\"'\",'``','`',',','--','-','...',')','(',\"''\"]\n",
    "\n",
    "texts_df['vocD'] = texts_df.toks.apply(lambda row: [x for x in row if x not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "      <th>vocD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_orig</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>254</td>\n",
       "      <td>11.772727</td>\n",
       "      <td>2.045455</td>\n",
       "      <td>70.995530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_norm</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>250</td>\n",
       "      <td>11.590909</td>\n",
       "      <td>2.045455</td>\n",
       "      <td>70.775894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  C1_orig  I do agree to the statement that children brou...   \n",
       "1  C1_norm  I do agree to the statement that children brou...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "1  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len        MLC  \\\n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...       254  11.772727   \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...       250  11.590909   \n",
       "\n",
       "        CNC       vocD  \n",
       "0  2.045455  70.995530  \n",
       "1  2.045455  70.775894  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create vocD column\n",
    "\n",
    "texts_df['vocD'] = texts_df.lemmas_NLTK.apply(lex.vocd)\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical sophistication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Guiraud (AG)\n",
    "AG based on lemmas using a frequency list (PSL3) compiled from the PELIC learner corpus (see dissertation section 2.2.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['yesterday', 'yet', 'yogurt', 'you', 'young', 'your', 'yours', 'yourself', 'youth', 'zoo']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in PSL3 list for manual checking of items in texts that are off list\n",
    "\n",
    "f = open(\"../docs/psl3.txt\", \"r\")\n",
    "PSL3 = f.read()\n",
    "PSL3 = sorted(PSL3.split('\\n'))\n",
    "len(PSL3)\n",
    "PSL3[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "      <th>vocD</th>\n",
       "      <th>AG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_orig</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>254</td>\n",
       "      <td>11.772727</td>\n",
       "      <td>2.045455</td>\n",
       "      <td>70.995530</td>\n",
       "      <td>1.443148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_norm</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>250</td>\n",
       "      <td>11.590909</td>\n",
       "      <td>2.045455</td>\n",
       "      <td>70.775894</td>\n",
       "      <td>1.454648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  C1_orig  I do agree to the statement that children brou...   \n",
       "1  C1_norm  I do agree to the statement that children brou...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "1  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len        MLC  \\\n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...       254  11.772727   \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...       250  11.590909   \n",
       "\n",
       "        CNC       vocD        AG  \n",
       "0  2.045455  70.995530  1.443148  \n",
       "1  2.045455  70.775894  1.454648  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create AG column (punctuation removed)\n",
    "\n",
    "texts_df['AG'] = texts_df.lemmas_NLTK.apply(lambda row: [x for x in row if x not in punctuation]).apply(\n",
    "    lex.adv_guiraud,freq_list = 'PSL3')\n",
    "\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual diversity\n",
    "\n",
    "Analysis using [TAALES](https://www.linguisticanalysistools.org/taales.html). Based on previous research, one metric is the focus: contextual diversity as in Monteiro et al. (2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in TAALES analysis\n",
    "\n",
    "TAALES = pd.read_csv(\"../docs/C1_TAALES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename files to match texts_df\n",
    "\n",
    "TAALES.Filename = TAALES.Filename.map(file_names)\n",
    "TAALES = TAALES.loc[~TAALES.Filename.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>unigram_range</th>\n",
       "      <th>bigram_range</th>\n",
       "      <th>trigram_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_orig</td>\n",
       "      <td>0.590773</td>\n",
       "      <td>0.122303</td>\n",
       "      <td>0.019143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1_norm</td>\n",
       "      <td>0.588858</td>\n",
       "      <td>0.117178</td>\n",
       "      <td>0.018722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id  unigram_range  bigram_range  trigram_range\n",
       "1  C1_orig       0.590773      0.122303       0.019143\n",
       "3  C1_norm       0.588858      0.117178       0.018722"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only relevant contextual diversity columns and rename them\n",
    "\n",
    "TAALES = TAALES[['Filename','COCA_Academic_Range_AW','COCA_Academic_Bigram_Range','COCA_Academic_Trigram_Range']]\n",
    "TAALES = TAALES.rename(columns={\"Filename\": \"text_id\",'COCA_Academic_Range_AW':'unigram_range',\n",
    "                                'COCA_Academic_Bigram_Range':'bigram_range',\n",
    "                                'COCA_Academic_Trigram_Range':'trigram_range'})\n",
    "TAALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "      <th>vocD</th>\n",
       "      <th>AG</th>\n",
       "      <th>unigram_range</th>\n",
       "      <th>bigram_range</th>\n",
       "      <th>trigram_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_orig</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>254</td>\n",
       "      <td>11.772727</td>\n",
       "      <td>2.045455</td>\n",
       "      <td>70.995530</td>\n",
       "      <td>1.443148</td>\n",
       "      <td>0.590773</td>\n",
       "      <td>0.122303</td>\n",
       "      <td>0.019143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_norm</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>250</td>\n",
       "      <td>11.590909</td>\n",
       "      <td>2.045455</td>\n",
       "      <td>70.775894</td>\n",
       "      <td>1.454648</td>\n",
       "      <td>0.588858</td>\n",
       "      <td>0.117178</td>\n",
       "      <td>0.018722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  C1_orig  I do agree to the statement that children brou...   \n",
       "1  C1_norm  I do agree to the statement that children brou...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "1  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len        MLC  \\\n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...       254  11.772727   \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...       250  11.590909   \n",
       "\n",
       "        CNC       vocD        AG  unigram_range  bigram_range  trigram_range  \n",
       "0  2.045455  70.995530  1.443148       0.590773      0.122303       0.019143  \n",
       "1  2.045455  70.775894  1.454648       0.588858      0.117178       0.018722  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge TAALES data with texts_df\n",
    "\n",
    "texts_df = pd.merge(texts_df, TAALES, on='text_id')\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocation measures\n",
    "3 measures which make up 'CollGram' profile from Granger & Bestgen / Bestgen & Granger (2014):\n",
    "- mean MI\n",
    "- mean t-score\n",
    "- proportion or bigrams absent from reference corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract potential collocations in span 4\n",
    "\n",
    "def find_cols(lemma_list):\n",
    "    col_list = list(zip(lemma_list,lemma_list[1:]))+list(zip(lemma_list,lemma_list[2:]))\\\n",
    "    +list(zip(lemma_list,lemma_list[3:]))+list(zip(lemma_list,lemma_list[4:]))\n",
    "    return col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create possible collocations column\n",
    "\n",
    "texts_df['possible_cols'] = texts_df.lemmas_CLAWS.apply(find_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower-case (doesn't matter that 'I' gets lowered as not in collocate dict)\n",
    "\n",
    "texts_df['possible_cols'] = texts_df.possible_cols.apply(\n",
    "    lambda row: [((x[0][0].lower(),x[0][1]),(x[1][0].lower(),x[1][1])) for x in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((\"'realities\", 'n'), ('in', 'i')), ((\"'realities\", 'n'), ('life', 'n')), ((\"'realities\", 'n'), ('of', 'i')), ((\"'realities\", 'n'), ('their', 'a')), (('a', 'a'), ('a', 'a'))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[(('world', 'n'), ('organization', 'n')), (('would', 'v'), ('be', 'v')), (('would', 'v'), ('bill', 'n')), (('would', 'v'), ('gate', 'n')), (('would', 'v'), ('mister', 'n'))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "941"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of all possible collocations\n",
    "\n",
    "possible_cols = sorted(list(set([x for y in texts_df.possible_cols.to_list() for x in y])))\n",
    "possible_cols[:5]\n",
    "possible_cols[-5:]\n",
    "len(possible_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean MI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MI is not calculated for any bigrams with freq less than 5 or MI less than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column with MI for each possible collocation in MI dict\n",
    "\n",
    "texts_df['col_MI'] = texts_df.possible_cols.apply(lambda row: [(x,MI_dict[x]) for x in row if x in MI_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mean MI for each text based on tokens and types\n",
    "\n",
    "texts_df['mean_MI'] = texts_df.col_MI.apply(lambda row: np.mean([x[1] for x in row]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion of absent/low MI word combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column of two-word combinations not in collocation dict\n",
    "\n",
    "texts_df['absent'] = texts_df.possible_cols.apply(lambda row: [x for x in row if x not in col_freq_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find proportion of absent two-word combinations compared to total two-word combinations in the text\n",
    "\n",
    "texts_df['absent_prop'] = texts_df.absent.apply(lambda row: len(row)) / texts_df.possible_cols.apply(lambda row: len(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find proportion of absent two-word combination types compared to total two-word combination types in the text\n",
    "\n",
    "texts_df['absent_prop_types'] = texts_df.absent.apply(lambda row: len(set(row))) / texts_df.possible_cols.apply(lambda row: len(set(row)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean t-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column with t-score for each bigram\n",
    "\n",
    "texts_df['col_tscore'] = texts_df.possible_cols.apply(lambda row: [(x,tscore_dict[x]) for x in row if x in tscore_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mean t-score for each text based on tokens and types\n",
    "\n",
    "texts_df['mean_tscore'] = texts_df.col_tscore.apply(lambda row: np.mean([x[1] for x in row]))\n",
    "texts_df['mean_tscore_types'] = texts_df.col_tscore.apply(lambda row: np.mean([x[1] for x in set(row)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "      <th>vocD</th>\n",
       "      <th>AG</th>\n",
       "      <th>unigram_range</th>\n",
       "      <th>bigram_range</th>\n",
       "      <th>trigram_range</th>\n",
       "      <th>possible_cols</th>\n",
       "      <th>col_MI</th>\n",
       "      <th>mean_MI</th>\n",
       "      <th>absent</th>\n",
       "      <th>absent_prop</th>\n",
       "      <th>absent_prop_types</th>\n",
       "      <th>col_tscore</th>\n",
       "      <th>mean_tscore</th>\n",
       "      <th>mean_tscore_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_orig</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>254</td>\n",
       "      <td>11.772727</td>\n",
       "      <td>2.045455</td>\n",
       "      <td>70.995530</td>\n",
       "      <td>1.443148</td>\n",
       "      <td>0.590773</td>\n",
       "      <td>0.122303</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>[((i, p), (do, v)), ((do, v), (agree, v)), ((a...</td>\n",
       "      <td>[((('expose', 'v'), ('to', 'i')), 2.4), ((('li...</td>\n",
       "      <td>3.259730</td>\n",
       "      <td>[((i, p), (do, v)), ((do, v), (agree, v)), ((a...</td>\n",
       "      <td>0.926441</td>\n",
       "      <td>0.928879</td>\n",
       "      <td>[((('expose', 'v'), ('to', 'i')), 133.938), ((...</td>\n",
       "      <td>93.616959</td>\n",
       "      <td>96.967682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_norm</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>250</td>\n",
       "      <td>11.590909</td>\n",
       "      <td>2.045455</td>\n",
       "      <td>70.775894</td>\n",
       "      <td>1.454648</td>\n",
       "      <td>0.588858</td>\n",
       "      <td>0.117178</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>[((i, p), (do, v)), ((do, v), (agree, v)), ((a...</td>\n",
       "      <td>[((('expose', 'v'), ('to', 'i')), 2.4), ((('li...</td>\n",
       "      <td>3.229444</td>\n",
       "      <td>[((i, p), (do, v)), ((do, v), (agree, v)), ((a...</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.930055</td>\n",
       "      <td>[((('expose', 'v'), ('to', 'i')), 133.938), ((...</td>\n",
       "      <td>92.030778</td>\n",
       "      <td>95.287937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  C1_orig  I do agree to the statement that children brou...   \n",
       "1  C1_norm  I do agree to the statement that children brou...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "1  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len        MLC  \\\n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...       254  11.772727   \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...       250  11.590909   \n",
       "\n",
       "        CNC       vocD        AG  unigram_range  bigram_range  trigram_range  \\\n",
       "0  2.045455  70.995530  1.443148       0.590773      0.122303       0.019143   \n",
       "1  2.045455  70.775894  1.454648       0.588858      0.117178       0.018722   \n",
       "\n",
       "                                       possible_cols  \\\n",
       "0  [((i, p), (do, v)), ((do, v), (agree, v)), ((a...   \n",
       "1  [((i, p), (do, v)), ((do, v), (agree, v)), ((a...   \n",
       "\n",
       "                                              col_MI   mean_MI  \\\n",
       "0  [((('expose', 'v'), ('to', 'i')), 2.4), ((('li...  3.259730   \n",
       "1  [((('expose', 'v'), ('to', 'i')), 2.4), ((('li...  3.229444   \n",
       "\n",
       "                                              absent  absent_prop  \\\n",
       "0  [((i, p), (do, v)), ((do, v), (agree, v)), ((a...     0.926441   \n",
       "1  [((i, p), (do, v)), ((do, v), (agree, v)), ((a...     0.927273   \n",
       "\n",
       "   absent_prop_types                                         col_tscore  \\\n",
       "0           0.928879  [((('expose', 'v'), ('to', 'i')), 133.938), ((...   \n",
       "1           0.930055  [((('expose', 'v'), ('to', 'i')), 133.938), ((...   \n",
       "\n",
       "   mean_tscore  mean_tscore_types  \n",
       "0    93.616959          96.967682  \n",
       "1    92.030778          95.287937  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "Grammatical accuracy and collocational accuracy. Errors manually annotated and counted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grammatical accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create lists of manually identified errors\n",
    "\n",
    "C1_orig_grammar = ['are taught necessary skills','families also are highly motivated']\n",
    "C1_norm_grammar = ['are taught necessary skills','families also are highly motivated']\n",
    "\n",
    "len(C1_orig_grammar)\n",
    "len(C1_norm_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grammatical accuracy column\n",
    "\n",
    "grammar_dict = {'C1_orig':len(C1_orig_grammar),'C1_norm':len(C1_norm_grammar)}\n",
    "\n",
    "texts_df['grammar_errors'] = texts_df.text_id.map(grammar_dict)\n",
    "texts_df['grammar_errors_per_100'] = (texts_df.grammar_errors/texts_df.text_len)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add punctuation column (manually counted)\n",
    "\n",
    "punc_dict = {'C1_orig':8,'C1_norm':8}\n",
    "\n",
    "texts_df['punc_errors'] = texts_df.text_id.map(punc_dict)\n",
    "texts_df['punc_errors_per_100'] = (texts_df.punc_errors/texts_df.text_len)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocational accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Record of collocation errors. MI calculations not comparable with two and three word collocations.\n",
    "\n",
    "C1_orig_errors = ['agree to the statement','in the weekends','collect some pocket money','computer organization','in summing up']\n",
    "C1_norm_errors = ['agree to the statement','in the weekends','collect some pocket money','computer organization','in summing up']\n",
    "\n",
    "len(C1_orig_errors)\n",
    "len(C1_norm_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accurate collocations (manually annotated)\n",
    "\n",
    "C1_orig_cols = ['poor families ','poor parents','are (prematurely) exposed to','learning to survive','low family income','sacrificing luxuries for','essential items','realities of life','home or social environment','serve as an example','taught necessary skills','skills for survival','from a very early age','contribute to','good example','accompany their parents','sell produce','at the market','in terms of','highly motivated','set high goals','improve their economic and social situation','A relevant example','founder of','impoverished background','poor backgrounds','robbed of their childhood','feel cheated','turn to crime','early exposure','family role models','direct contribution','sheer motivation']\n",
    "C1_norm_cols = ['poor families ','poor parents','are (prematurely) exposed to','learning to survive','low family income','sacrificing luxuries for','essential items','realities of life','home or social environment','serve as an example','taught necessary skills','skills for survival','from a very early age','contribute to','good example','accompany their parents','sell produce','at the market','in terms of','highly motivated','set high goals','improve their economic and social situation','A relevant example','founder of','impoverished background','poor backgrounds','robbed of their childhood','feel cheated','turn to crime','early exposure','family role models','direct contribution','sheer motivation']\n",
    "\n",
    "len(C1_orig_cols)\n",
    "len(C1_norm_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create error and accurate cols columns\n",
    "\n",
    "errors_dict = {'C1_orig':len(C1_orig_errors),'C1_norm':len(C1_norm_errors)}\n",
    "correct_dict = {'C1_orig':len(C1_orig_cols),'C1_norm':len(C1_norm_cols)}\n",
    "\n",
    "texts_df['col_errors'] = texts_df.text_id.map(errors_dict)\n",
    "texts_df['correct_cols'] = texts_df.text_id.map(correct_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create errors and correct cols per 100 words columns\n",
    "\n",
    "texts_df['col_errors_per_100'] = (texts_df.col_errors/texts_df.text_len)*100\n",
    "texts_df['correct_cols_per_100'] = (texts_df.correct_cols/texts_df.text_len)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "      <th>vocD</th>\n",
       "      <th>AG</th>\n",
       "      <th>unigram_range</th>\n",
       "      <th>bigram_range</th>\n",
       "      <th>trigram_range</th>\n",
       "      <th>possible_cols</th>\n",
       "      <th>col_MI</th>\n",
       "      <th>mean_MI</th>\n",
       "      <th>absent</th>\n",
       "      <th>absent_prop</th>\n",
       "      <th>absent_prop_types</th>\n",
       "      <th>col_tscore</th>\n",
       "      <th>mean_tscore</th>\n",
       "      <th>mean_tscore_types</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>grammar_errors_per_100</th>\n",
       "      <th>punc_errors</th>\n",
       "      <th>punc_errors_per_100</th>\n",
       "      <th>col_errors</th>\n",
       "      <th>correct_cols</th>\n",
       "      <th>col_errors_per_100</th>\n",
       "      <th>correct_cols_per_100</th>\n",
       "      <th>bad_cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_orig</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>254</td>\n",
       "      <td>11.772727</td>\n",
       "      <td>2.045455</td>\n",
       "      <td>70.995530</td>\n",
       "      <td>1.443148</td>\n",
       "      <td>0.590773</td>\n",
       "      <td>0.122303</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>[((i, p), (do, v)), ((do, v), (agree, v)), ((a...</td>\n",
       "      <td>[((('expose', 'v'), ('to', 'i')), 2.4), ((('li...</td>\n",
       "      <td>3.259730</td>\n",
       "      <td>[((i, p), (do, v)), ((do, v), (agree, v)), ((a...</td>\n",
       "      <td>0.926441</td>\n",
       "      <td>0.928879</td>\n",
       "      <td>[((('expose', 'v'), ('to', 'i')), 133.938), ((...</td>\n",
       "      <td>93.616959</td>\n",
       "      <td>96.967682</td>\n",
       "      <td>2</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>8</td>\n",
       "      <td>3.149606</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>1.968504</td>\n",
       "      <td>12.992126</td>\n",
       "      <td>[agree to the statement, in the weekends, coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_norm</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>250</td>\n",
       "      <td>11.590909</td>\n",
       "      <td>2.045455</td>\n",
       "      <td>70.775894</td>\n",
       "      <td>1.454648</td>\n",
       "      <td>0.588858</td>\n",
       "      <td>0.117178</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>[((i, p), (do, v)), ((do, v), (agree, v)), ((a...</td>\n",
       "      <td>[((('expose', 'v'), ('to', 'i')), 2.4), ((('li...</td>\n",
       "      <td>3.229444</td>\n",
       "      <td>[((i, p), (do, v)), ((do, v), (agree, v)), ((a...</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>0.930055</td>\n",
       "      <td>[((('expose', 'v'), ('to', 'i')), 133.938), ((...</td>\n",
       "      <td>92.030778</td>\n",
       "      <td>95.287937</td>\n",
       "      <td>2</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>8</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>[agree to the statement, in the weekends, coll...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  C1_orig  I do agree to the statement that children brou...   \n",
       "1  C1_norm  I do agree to the statement that children brou...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "1  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len        MLC  \\\n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...       254  11.772727   \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...       250  11.590909   \n",
       "\n",
       "        CNC       vocD        AG  unigram_range  bigram_range  trigram_range  \\\n",
       "0  2.045455  70.995530  1.443148       0.590773      0.122303       0.019143   \n",
       "1  2.045455  70.775894  1.454648       0.588858      0.117178       0.018722   \n",
       "\n",
       "                                       possible_cols  \\\n",
       "0  [((i, p), (do, v)), ((do, v), (agree, v)), ((a...   \n",
       "1  [((i, p), (do, v)), ((do, v), (agree, v)), ((a...   \n",
       "\n",
       "                                              col_MI   mean_MI  \\\n",
       "0  [((('expose', 'v'), ('to', 'i')), 2.4), ((('li...  3.259730   \n",
       "1  [((('expose', 'v'), ('to', 'i')), 2.4), ((('li...  3.229444   \n",
       "\n",
       "                                              absent  absent_prop  \\\n",
       "0  [((i, p), (do, v)), ((do, v), (agree, v)), ((a...     0.926441   \n",
       "1  [((i, p), (do, v)), ((do, v), (agree, v)), ((a...     0.927273   \n",
       "\n",
       "   absent_prop_types                                         col_tscore  \\\n",
       "0           0.928879  [((('expose', 'v'), ('to', 'i')), 133.938), ((...   \n",
       "1           0.930055  [((('expose', 'v'), ('to', 'i')), 133.938), ((...   \n",
       "\n",
       "   mean_tscore  mean_tscore_types  grammar_errors  grammar_errors_per_100  \\\n",
       "0    93.616959          96.967682               2                0.787402   \n",
       "1    92.030778          95.287937               2                0.800000   \n",
       "\n",
       "   punc_errors  punc_errors_per_100  col_errors  correct_cols  \\\n",
       "0            8             3.149606           5            33   \n",
       "1            8             3.200000           5            33   \n",
       "\n",
       "   col_errors_per_100  correct_cols_per_100  \\\n",
       "0            1.968504             12.992126   \n",
       "1            2.000000             13.200000   \n",
       "\n",
       "                                            bad_cols  \n",
       "0  [agree to the statement, in the weekends, coll...  \n",
       "1  [agree to the statement, in the weekends, coll...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 'bad' cols column for future use\n",
    "\n",
    "texts_df['bad_cols'] = (C1_orig_errors,C1_norm_errors)\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocation frequency bands\n",
    "Percentage of collocations containing low/mid/high freq items.  \n",
    "- High = K1-2\n",
    "- Mid = K3-9\n",
    "- Low = K10+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize collocations\n",
    "\n",
    "C1_orig_cols_toks = [x.split() for x in C1_orig_cols]\n",
    "C1_norm_cols_toks = [x.split() for x in C1_norm_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['poor', 'families'], ['poor', 'parents'], ['are', '(prematurely)', 'exposed', 'to'], ['learning', 'to', 'survive'], ['low', 'family', 'income'], ['sacrificing', 'luxuries', 'for'], ['essential', 'items'], ['realities', 'of', 'life'], ['home', 'or', 'social', 'environment'], ['serve', 'as', 'an', 'example'], ['taught', 'necessary', 'skills'], ['skills', 'for', 'survival'], ['from', 'a', 'very', 'early', 'age'], ['contribute', 'to'], ['good', 'example'], ['accompany', 'their', 'parents'], ['sell', 'produce'], ['at', 'the', 'market'], ['in', 'terms', 'of'], ['highly', 'motivated'], ['set', 'high', 'goals'], ['improve', 'their', 'economic', 'and', 'social', 'situation'], ['A', 'relevant', 'example'], ['founder', 'of'], ['impoverished', 'background'], ['poor', 'backgrounds'], ['robbed', 'of', 'their', 'childhood'], ['feel', 'cheated'], ['turn', 'to', 'crime'], ['early', 'exposure'], ['family', 'role', 'models'], ['direct', 'contribution'], ['sheer', 'motivation']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[['poor', 'families'], ['poor', 'parents'], ['are', '(prematurely)', 'exposed', 'to'], ['learning', 'to', 'survive'], ['low', 'family', 'income'], ['sacrificing', 'luxuries', 'for'], ['essential', 'items'], ['realities', 'of', 'life'], ['home', 'or', 'social', 'environment'], ['serve', 'as', 'an', 'example'], ['taught', 'necessary', 'skills'], ['skills', 'for', 'survival'], ['from', 'a', 'very', 'early', 'age'], ['contribute', 'to'], ['good', 'example'], ['accompany', 'their', 'parents'], ['sell', 'produce'], ['at', 'the', 'market'], ['in', 'terms', 'of'], ['highly', 'motivated'], ['set', 'high', 'goals'], ['improve', 'their', 'economic', 'and', 'social', 'situation'], ['A', 'relevant', 'example'], ['founder', 'of'], ['impoverished', 'background'], ['poor', 'backgrounds'], ['robbed', 'of', 'their', 'childhood'], ['feel', 'cheated'], ['turn', 'to', 'crime'], ['early', 'exposure'], ['family', 'role', 'models'], ['direct', 'contribution'], ['sheer', 'motivation']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1_orig_cols_toks\n",
    "C1_norm_cols_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collocations with PoS (manually lemmatized and tagged based on above)\n",
    "\n",
    "C1_orig_cols_toks_POS = [[('poor','j'), ('family','n')],\n",
    "                         [('poor','j'), ('parent','n')],\n",
    "                         [('be','v'), ('prematurely','r'), ('expose','v'), ('to','i')],\n",
    "                         [('learn','v'), ('to','t'), ('survive','v')],\n",
    "                         [('low','j'), ('family','n'), ('income','n')],\n",
    "                         [('sacrifice','v'), ('luxury','n'), ('for','i')],\n",
    "                         [('essential','j'), ('item','n')],\n",
    "                         [('reality','n'), ('of','i'), ('life','n')],\n",
    "                         [('home','n'), ('or','c'), ('social','j'), ('environment','n')],\n",
    "                         [('serve','v'), ('as','i'), ('a','a'), ('example','n')],\n",
    "                         [('teach','v'), ('necessary','j'), ('skill','n')],\n",
    "                         [('skill','n'), ('for','i'), ('survival','n')],\n",
    "                         [('from','i'), ('a','a'), ('very','r'), ('early','j'), ('age','n')],\n",
    "                         [('contribute','v'), ('to','i')],\n",
    "                         [('good','j'), ('example','n')],\n",
    "                         [('accompany','v'), ('their','a'), ('parent','n')],\n",
    "                         [('sell','v'), ('produce','n')],\n",
    "                         [('at','i'), ('the','a'), ('market','n')],\n",
    "                         [('in','i'), ('term','n'), ('of','i')],\n",
    "                         [('highly','r'), ('motivated','j')],\n",
    "                         [('set','v'), ('high','j'), ('goal','n')],\n",
    "                         [('improve','v'), ('their','a'), ('economic','j'), ('and','c'), ('social','j'), ('situation','n')],\n",
    "                         [('a','a'), ('relevant','j'), ('example','n')],\n",
    "                         [('founder','n'), ('of','i')],\n",
    "                         [('impoverished','j'), ('background','n')],\n",
    "                         [('poor','j'), ('background','n')],\n",
    "                         [('rob','v'),('of','i'), ('their','a'), ('childhood','n')],\n",
    "                         [('feel','v'), ('cheat','v')],\n",
    "                         [('turn','v'), ('to','i'), ('crime','n')],\n",
    "                         [('early','j'), ('exposure','n')],\n",
    "                         [('family','n'), ('role','n'), ('model','n')],\n",
    "                         [('direct','j'), ('contribution','n')],\n",
    "                         [('sheer','j'), ('motivation','n')]]\n",
    "\n",
    "C1_norm_cols_toks_POS = C1_orig_cols_toks_POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create collocation dict\n",
    "\n",
    "col_dict = {'C1_orig':C1_orig_cols_toks_POS,'C1_norm':C1_norm_cols_toks_POS}\n",
    "\n",
    "# Create column with collocations\n",
    "\n",
    "texts_df['cols'] = texts_df.text_id.map(col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column of the freq bands of the highest kband item in each collocation\n",
    "\n",
    "texts_df['col_kband'] = texts_df.cols.apply(\n",
    "    lambda row:[sorted([kband_dict[y] for y in x],reverse=True)[0] for x in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create (kband, cols) tuples\n",
    "\n",
    "texts_df['kband_cols'] = list(zip(texts_df.col_kband,texts_df.cols))\n",
    "texts_df['kband_cols'] = texts_df['kband_cols'].apply(lambda row: list(zip(row[0],row[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Kbands\n",
    "\n",
    "high_freq_K = list(range(1,3))\n",
    "mid_freq_K = list(range(3,10))\n",
    "low_freq_K = list(range(10,101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns of percentages of cols that contain low, med, high kband items (highest only)\n",
    "\n",
    "texts_df['K10to16_cols'] = texts_df.col_kband.apply(lambda row: len([x for x in row if x in(low_freq_K)]))\n",
    "texts_df['K3to9_cols'] = texts_df.col_kband.apply(lambda row: len([x for x in row if x in(mid_freq_K)]))\n",
    "texts_df['K1to2_cols'] = texts_df.col_kband.apply(lambda row: len([x for x in row if x in(high_freq_K)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add percent columns\n",
    "\n",
    "texts_df['K10to16_p'] = texts_df['K10to16_cols']/(texts_df['K10to16_cols']+texts_df['K3to9_cols']+texts_df['K1to2_cols'])\n",
    "texts_df['K3to9_p'] = texts_df['K3to9_cols']/(texts_df['K10to16_cols']+texts_df['K3to9_cols']+texts_df['K1to2_cols'])\n",
    "texts_df['K1to2_p'] = texts_df['K1to2_cols']/(texts_df['K10to16_cols']+texts_df['K3to9_cols']+texts_df['K1to2_cols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate columns with low/mid/high cols for ease of viewing\n",
    "\n",
    "texts_df['K1to2_cols_K'] = texts_df.kband_cols.apply(lambda row: [x for x in row if x[0] <= 2])\n",
    "texts_df['K3to9_cols_K'] = texts_df.kband_cols.apply(lambda row: [x for x in row if 10 > x[0] > 2])\n",
    "texts_df['K10to16_cols_K'] = texts_df.kband_cols.apply(lambda row: [x for x in row if x[0] > 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "      <th>toks</th>\n",
       "      <th>tok_POS_NLTK</th>\n",
       "      <th>toks_POS_CLAWS</th>\n",
       "      <th>lemmas_NLTK</th>\n",
       "      <th>lemmas_CLAWS</th>\n",
       "      <th>text_len</th>\n",
       "      <th>MLC</th>\n",
       "      <th>CNC</th>\n",
       "      <th>vocD</th>\n",
       "      <th>AG</th>\n",
       "      <th>unigram_range</th>\n",
       "      <th>bigram_range</th>\n",
       "      <th>trigram_range</th>\n",
       "      <th>possible_cols</th>\n",
       "      <th>col_MI</th>\n",
       "      <th>mean_MI</th>\n",
       "      <th>absent</th>\n",
       "      <th>absent_prop</th>\n",
       "      <th>absent_prop_types</th>\n",
       "      <th>col_tscore</th>\n",
       "      <th>mean_tscore</th>\n",
       "      <th>mean_tscore_types</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>grammar_errors_per_100</th>\n",
       "      <th>punc_errors</th>\n",
       "      <th>punc_errors_per_100</th>\n",
       "      <th>col_errors</th>\n",
       "      <th>correct_cols</th>\n",
       "      <th>col_errors_per_100</th>\n",
       "      <th>correct_cols_per_100</th>\n",
       "      <th>bad_cols</th>\n",
       "      <th>cols</th>\n",
       "      <th>col_kband</th>\n",
       "      <th>kband_cols</th>\n",
       "      <th>K10to16_cols</th>\n",
       "      <th>K3to9_cols</th>\n",
       "      <th>K1to2_cols</th>\n",
       "      <th>K10to16_p</th>\n",
       "      <th>K3to9_p</th>\n",
       "      <th>K1to2_p</th>\n",
       "      <th>K1to2_cols_K</th>\n",
       "      <th>K3to9_cols_K</th>\n",
       "      <th>K10to16_cols_K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1_orig</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>254</td>\n",
       "      <td>11.773</td>\n",
       "      <td>2.045</td>\n",
       "      <td>70.996</td>\n",
       "      <td>1.443</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.019</td>\n",
       "      <td>[((i, p), (do, v)), ((do, v), (agree, v)), ((a...</td>\n",
       "      <td>[((('expose', 'v'), ('to', 'i')), 2.4), ((('li...</td>\n",
       "      <td>3.260</td>\n",
       "      <td>[((i, p), (do, v)), ((do, v), (agree, v)), ((a...</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.929</td>\n",
       "      <td>[((('expose', 'v'), ('to', 'i')), 133.938), ((...</td>\n",
       "      <td>93.617</td>\n",
       "      <td>96.968</td>\n",
       "      <td>2</td>\n",
       "      <td>0.787</td>\n",
       "      <td>8</td>\n",
       "      <td>3.15</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>1.969</td>\n",
       "      <td>12.992</td>\n",
       "      <td>[agree to the statement, in the weekends, coll...</td>\n",
       "      <td>[[(poor, j), (family, n)], [(poor, j), (parent...</td>\n",
       "      <td>[1, 1, 14, 2, 2, 7, 3, 1, 1, 1, 2, 3, 1, 2, 1,...</td>\n",
       "      <td>[(1, [('poor', 'j'), ('family', 'n')]), (1, [(...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.545</td>\n",
       "      <td>[(1, [('poor', 'j'), ('family', 'n')]), (1, [(...</td>\n",
       "      <td>[(7, [('sacrifice', 'v'), ('luxury', 'n'), ('f...</td>\n",
       "      <td>[(14, [('be', 'v'), ('prematurely', 'r'), ('ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1_norm</td>\n",
       "      <td>I do agree to the statement that children brou...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, PRP), (do, VBP), (agree, VB), (to, IN), (...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>[I, do, agree, to, the, statement, that, child...</td>\n",
       "      <td>[(I, p), (do, v), (agree, v), (to, i), (the, a...</td>\n",
       "      <td>250</td>\n",
       "      <td>11.591</td>\n",
       "      <td>2.045</td>\n",
       "      <td>70.776</td>\n",
       "      <td>1.455</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.019</td>\n",
       "      <td>[((i, p), (do, v)), ((do, v), (agree, v)), ((a...</td>\n",
       "      <td>[((('expose', 'v'), ('to', 'i')), 2.4), ((('li...</td>\n",
       "      <td>3.229</td>\n",
       "      <td>[((i, p), (do, v)), ((do, v), (agree, v)), ((a...</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.930</td>\n",
       "      <td>[((('expose', 'v'), ('to', 'i')), 133.938), ((...</td>\n",
       "      <td>92.031</td>\n",
       "      <td>95.288</td>\n",
       "      <td>2</td>\n",
       "      <td>0.800</td>\n",
       "      <td>8</td>\n",
       "      <td>3.20</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>2.000</td>\n",
       "      <td>13.200</td>\n",
       "      <td>[agree to the statement, in the weekends, coll...</td>\n",
       "      <td>[[(poor, j), (family, n)], [(poor, j), (parent...</td>\n",
       "      <td>[1, 1, 14, 2, 2, 7, 3, 1, 1, 1, 2, 3, 1, 2, 1,...</td>\n",
       "      <td>[(1, [('poor', 'j'), ('family', 'n')]), (1, [(...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.545</td>\n",
       "      <td>[(1, [('poor', 'j'), ('family', 'n')]), (1, [(...</td>\n",
       "      <td>[(7, [('sacrifice', 'v'), ('luxury', 'n'), ('f...</td>\n",
       "      <td>[(14, [('be', 'v'), ('prematurely', 'r'), ('ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                               text  \\\n",
       "0  C1_orig  I do agree to the statement that children brou...   \n",
       "1  C1_norm  I do agree to the statement that children brou...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        tok_POS_NLTK  \\\n",
       "0  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "1  [(I, PRP), (do, VBP), (agree, VB), (to, IN), (...   \n",
       "\n",
       "                                      toks_POS_CLAWS  \\\n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...   \n",
       "\n",
       "                                         lemmas_NLTK  \\\n",
       "0  [I, do, agree, to, the, statement, that, child...   \n",
       "1  [I, do, agree, to, the, statement, that, child...   \n",
       "\n",
       "                                        lemmas_CLAWS  text_len     MLC    CNC  \\\n",
       "0  [(I, p), (do, v), (agree, v), (to, i), (the, a...       254  11.773  2.045   \n",
       "1  [(I, p), (do, v), (agree, v), (to, i), (the, a...       250  11.591  2.045   \n",
       "\n",
       "     vocD     AG  unigram_range  bigram_range  trigram_range  \\\n",
       "0  70.996  1.443          0.591         0.122          0.019   \n",
       "1  70.776  1.455          0.589         0.117          0.019   \n",
       "\n",
       "                                       possible_cols  \\\n",
       "0  [((i, p), (do, v)), ((do, v), (agree, v)), ((a...   \n",
       "1  [((i, p), (do, v)), ((do, v), (agree, v)), ((a...   \n",
       "\n",
       "                                              col_MI  mean_MI  \\\n",
       "0  [((('expose', 'v'), ('to', 'i')), 2.4), ((('li...    3.260   \n",
       "1  [((('expose', 'v'), ('to', 'i')), 2.4), ((('li...    3.229   \n",
       "\n",
       "                                              absent  absent_prop  \\\n",
       "0  [((i, p), (do, v)), ((do, v), (agree, v)), ((a...        0.926   \n",
       "1  [((i, p), (do, v)), ((do, v), (agree, v)), ((a...        0.927   \n",
       "\n",
       "   absent_prop_types                                         col_tscore  \\\n",
       "0              0.929  [((('expose', 'v'), ('to', 'i')), 133.938), ((...   \n",
       "1              0.930  [((('expose', 'v'), ('to', 'i')), 133.938), ((...   \n",
       "\n",
       "   mean_tscore  mean_tscore_types  grammar_errors  grammar_errors_per_100  \\\n",
       "0       93.617             96.968               2                   0.787   \n",
       "1       92.031             95.288               2                   0.800   \n",
       "\n",
       "   punc_errors  punc_errors_per_100  col_errors  correct_cols  \\\n",
       "0            8                 3.15           5            33   \n",
       "1            8                 3.20           5            33   \n",
       "\n",
       "   col_errors_per_100  correct_cols_per_100  \\\n",
       "0               1.969                12.992   \n",
       "1               2.000                13.200   \n",
       "\n",
       "                                            bad_cols  \\\n",
       "0  [agree to the statement, in the weekends, coll...   \n",
       "1  [agree to the statement, in the weekends, coll...   \n",
       "\n",
       "                                                cols  \\\n",
       "0  [[(poor, j), (family, n)], [(poor, j), (parent...   \n",
       "1  [[(poor, j), (family, n)], [(poor, j), (parent...   \n",
       "\n",
       "                                           col_kband  \\\n",
       "0  [1, 1, 14, 2, 2, 7, 3, 1, 1, 1, 2, 3, 1, 2, 1,...   \n",
       "1  [1, 1, 14, 2, 2, 7, 3, 1, 1, 1, 2, 3, 1, 2, 1,...   \n",
       "\n",
       "                                          kband_cols  K10to16_cols  \\\n",
       "0  [(1, [('poor', 'j'), ('family', 'n')]), (1, [(...             3   \n",
       "1  [(1, [('poor', 'j'), ('family', 'n')]), (1, [(...             3   \n",
       "\n",
       "   K3to9_cols  K1to2_cols  K10to16_p  K3to9_p  K1to2_p  \\\n",
       "0          12          18      0.091    0.364    0.545   \n",
       "1          12          18      0.091    0.364    0.545   \n",
       "\n",
       "                                        K1to2_cols_K  \\\n",
       "0  [(1, [('poor', 'j'), ('family', 'n')]), (1, [(...   \n",
       "1  [(1, [('poor', 'j'), ('family', 'n')]), (1, [(...   \n",
       "\n",
       "                                        K3to9_cols_K  \\\n",
       "0  [(7, [('sacrifice', 'v'), ('luxury', 'n'), ('f...   \n",
       "1  [(7, [('sacrifice', 'v'), ('luxury', 'n'), ('f...   \n",
       "\n",
       "                                      K10to16_cols_K  \n",
       "0  [(14, [('be', 'v'), ('prematurely', 'r'), ('ex...  \n",
       "1  [(14, [('be', 'v'), ('prematurely', 'r'), ('ex...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round all stats to 3 digits for ease of use\n",
    "\n",
    "texts_df = round(texts_df,3)\n",
    "texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing length\n",
    "\n",
    "Results of comparison between original and normalized versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function for finding range of + or - 5%\n",
    "\n",
    "def find_range(stat):\n",
    "    low = str(round(stat*.95,2))\n",
    "    high = str(round(stat*1.05,2))\n",
    "    stat_range = low + ' - ' + high\n",
    "    return stat_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[70.996, 70.776]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'67.45 - 74.55'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocD: mod within 5% of orig (remember that changes slightly every time calculated as based on samples)\n",
    "\n",
    "C1_vocd = texts_df['vocD'].to_list()\n",
    "C1_vocd \n",
    "\n",
    "find_range(C1_vocd[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.443, 1.455]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'1.37 - 1.52'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AG (PSL): mod within 5% of orig\n",
    "\n",
    "C1_AG = texts_df['AG'].to_list()\n",
    "C1_AG\n",
    "\n",
    "find_range(C1_AG[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.26, 3.229]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'3.1 - 3.42'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean MI (words): mod within 5% of orig\n",
    "\n",
    "C1_mean_MI = texts_df['mean_MI'].to_list()\n",
    "C1_mean_MI\n",
    "\n",
    "find_range(C1_mean_MI[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[93.617, 92.031]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'88.94 - 98.3'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean t-score (words): mod within 5% of orig\n",
    "\n",
    "C1_mean_t_score = texts_df['mean_tscore'].to_list()\n",
    "C1_mean_t_score\n",
    "\n",
    "find_range(C1_mean_t_score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.926, 0.927]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.88 - 0.97'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean proportion of bigrams (words): mod within 5% of orig or closest possible\n",
    "\n",
    "C1_absent_prop = texts_df['absent_prop'].to_list()\n",
    "C1_absent_prop\n",
    "\n",
    "find_range(C1_absent_prop[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.787, 0.8]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.75 - 0.83'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grammar errors per 100: mod within 5% of orig\n",
    "\n",
    "C1_grammar_errors_per_100 = texts_df['grammar_errors_per_100'].to_list()\n",
    "C1_grammar_errors_per_100\n",
    "\n",
    "find_range(C1_grammar_errors_per_100[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.15, 3.2]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'2.99 - 3.31'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Punctuation errors per 100: mod within 5% of orig\n",
    "\n",
    "C1_punc_errors_per_100 = texts_df['punc_errors_per_100'].to_list()\n",
    "C1_punc_errors_per_100\n",
    "\n",
    "find_range(C1_punc_errors_per_100[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.969, 2.0]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'1.87 - 2.07'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collocation errors per 100: mod within 5% of orig\n",
    "\n",
    "C1_col_errors_per_100 = texts_df['col_errors_per_100'].to_list()\n",
    "C1_col_errors_per_100\n",
    "\n",
    "find_range(C1_col_errors_per_100[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.992, 13.2]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'12.34 - 13.64'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accurate colls per 100\n",
    "\n",
    "C1_correct_cols_per_100 = texts_df['correct_cols_per_100'].to_list()\n",
    "C1_correct_cols_per_100\n",
    "\n",
    "find_range(C1_correct_cols_per_100[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.091, 0.091]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.09 - 0.1'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K10-16 cols percent\n",
    "\n",
    "C1_K10to16_p = texts_df['K10to16_p'].to_list()\n",
    "C1_K10to16_p\n",
    "\n",
    "find_range(C1_K10to16_p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.364, 0.364]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.35 - 0.38'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K3-9 cols percent\n",
    "\n",
    "C1_K3to9_p = texts_df['K3to9_p'].to_list()\n",
    "C1_K3to9_p\n",
    "\n",
    "find_range(C1_K3to9_p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.545, 0.545]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.52 - 0.57'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K1-2 cols percent\n",
    "\n",
    "C1_K1to2_p = texts_df['K1to2_p'].to_list()\n",
    "C1_K1to2_p\n",
    "\n",
    "find_range(C1_K1to2_p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.122, 0.117]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'0.12 - 0.13'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bigram range: mod within 5% of orig\n",
    "\n",
    "C1_bigram_range = texts_df['bigram_range'].to_list()\n",
    "C1_bigram_range\n",
    "\n",
    "find_range(C1_bigram_range[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.045, 2.045]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'1.94 - 2.15'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNC: mod within 5% of orig\n",
    "\n",
    "C1_CNC = texts_df['CNC'].to_list()\n",
    "C1_CNC\n",
    "\n",
    "find_range(C1_CNC[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11.773, 11.591]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'11.18 - 12.36'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLC: mod within 5% of orig\n",
    "\n",
    "C1_MLC = texts_df['MLC'].to_list()\n",
    "C1_MLC\n",
    "\n",
    "find_range(C1_MLC[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison with relevant stats only\n",
    "\n",
    "texts_final = texts_df[['text_id','text','lemmas_NLTK','lemmas_CLAWS','text_len','MLC','CNC','grammar_errors_per_100',\n",
    "                        'punc_errors_per_100','vocD','AG','bigram_range','mean_MI','absent_prop',\n",
    "                        'mean_tscore','col_errors_per_100','correct_cols_per_100','K10to16_p','K3to9_p','K1to2_p',\n",
    "                        'kband_cols', 'K1to2_cols','K3to9_cols','K10to16_cols',\n",
    "                        'K1to2_cols_K','K3to9_cols_K','K10to16_cols_K','bad_cols']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../docs/C1_orig&norm.pkl']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pickle for later use\n",
    "\n",
    "joblib.dump(texts_final ,'../docs/C1_orig&norm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../docs/C1_cols.pkl']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pickle possible cols for collocation identification notebook\n",
    "\n",
    "C1_cols = texts_df[['text_id','lemmas_CLAWS','possible_cols']]\n",
    "\n",
    "joblib.dump(C1_cols ,'../docs/C1_cols.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Normalizing-B1-original-text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
